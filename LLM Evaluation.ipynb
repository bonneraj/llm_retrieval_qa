{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67ddcb71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xmltodict in c:\\users\\alex\\anaconda3\\lib\\site-packages (0.13.0)\n",
      "Requirement already satisfied: bs4 in c:\\users\\alex\\anaconda3\\lib\\site-packages (0.0.1)\n",
      "Requirement already satisfied: langchain==0.0.271 in c:\\users\\alex\\anaconda3\\lib\\site-packages (0.0.271)\n",
      "Requirement already satisfied: typing-inspect==0.8.0 in c:\\users\\alex\\anaconda3\\lib\\site-packages (0.8.0)\n",
      "Requirement already satisfied: typing_extensions==4.5.0 in c:\\users\\alex\\anaconda3\\lib\\site-packages (4.5.0)\n",
      "Requirement already satisfied: newspaper3k in c:\\users\\alex\\anaconda3\\lib\\site-packages (0.2.8)\n",
      "Requirement already satisfied: sentence-transformers==2.2.2 in c:\\users\\alex\\anaconda3\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: chromadb==0.3.25 in c:\\users\\alex\\anaconda3\\lib\\site-packages (0.3.25)\n",
      "Requirement already satisfied: tensorflow in c:\\users\\alex\\anaconda3\\lib\\site-packages (2.13.0)\n",
      "Requirement already satisfied: transformers in c:\\users\\alex\\anaconda3\\lib\\site-packages (4.24.0)\n",
      "Requirement already satisfied: mlflow==2.4.0 in c:\\users\\alex\\anaconda3\\lib\\site-packages (2.4.0)\n",
      "Requirement already satisfied: langsmith<0.1.0,>=0.0.21 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from langchain==0.0.271) (0.0.26)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from langchain==0.0.271) (1.4.39)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from langchain==0.0.271) (4.0.3)\n",
      "Requirement already satisfied: dataclasses-json<0.6.0,>=0.5.7 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from langchain==0.0.271) (0.5.14)\n",
      "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from langchain==0.0.271) (2.8.4)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from langchain==0.0.271) (8.2.3)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from langchain==0.0.271) (3.8.5)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from langchain==0.0.271) (1.23.5)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from langchain==0.0.271) (2.28.1)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from langchain==0.0.271) (6.0)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from langchain==0.0.271) (1.10.8)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from typing-inspect==0.8.0) (0.4.3)\n",
      "Requirement already satisfied: scipy in c:\\users\\alex\\anaconda3\\lib\\site-packages (from sentence-transformers==2.2.2) (1.10.0)\n",
      "Requirement already satisfied: torch>=1.6.0 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from sentence-transformers==2.2.2) (2.0.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\alex\\anaconda3\\lib\\site-packages (from sentence-transformers==2.2.2) (1.2.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.4.0 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from sentence-transformers==2.2.2) (0.10.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\alex\\anaconda3\\lib\\site-packages (from sentence-transformers==2.2.2) (4.66.1)\n",
      "Requirement already satisfied: torchvision in c:\\users\\alex\\anaconda3\\lib\\site-packages (from sentence-transformers==2.2.2) (0.15.2)\n",
      "Requirement already satisfied: sentencepiece in c:\\users\\alex\\anaconda3\\lib\\site-packages (from sentence-transformers==2.2.2) (0.1.99)\n",
      "Requirement already satisfied: nltk in c:\\users\\alex\\anaconda3\\lib\\site-packages (from sentence-transformers==2.2.2) (3.7)\n",
      "Requirement already satisfied: clickhouse-connect>=0.5.7 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from chromadb==0.3.25) (0.6.8)\n",
      "Requirement already satisfied: hnswlib>=0.7 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from chromadb==0.3.25) (0.7.0)\n",
      "Requirement already satisfied: pandas>=1.3 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from chromadb==0.3.25) (1.5.3)\n",
      "Requirement already satisfied: fastapi>=0.85.1 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from chromadb==0.3.25) (0.101.1)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from chromadb==0.3.25) (0.13.3)\n",
      "Requirement already satisfied: posthog>=2.4.0 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from chromadb==0.3.25) (3.0.1)\n",
      "Requirement already satisfied: duckdb>=0.7.1 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from chromadb==0.3.25) (0.8.1)\n",
      "Requirement already satisfied: overrides>=7.3.1 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from chromadb==0.3.25) (7.4.0)\n",
      "Requirement already satisfied: onnxruntime>=1.14.1 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from chromadb==0.3.25) (1.15.1)\n",
      "Requirement already satisfied: uvicorn[standard]>=0.18.3 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from chromadb==0.3.25) (0.23.2)\n",
      "Requirement already satisfied: markdown<4,>=3.3 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from mlflow==2.4.0) (3.4.1)\n",
      "Requirement already satisfied: gitpython<4,>=2.1.0 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from mlflow==2.4.0) (3.1.31)\n",
      "Requirement already satisfied: docker<7,>=4.0.0 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from mlflow==2.4.0) (6.1.2)\n",
      "Requirement already satisfied: pyarrow<13,>=4.0.0 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from mlflow==2.4.0) (11.0.0)\n",
      "Requirement already satisfied: matplotlib<4 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from mlflow==2.4.0) (3.7.0)\n",
      "Requirement already satisfied: waitress<3 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from mlflow==2.4.0) (2.1.2)\n",
      "Requirement already satisfied: click<9,>=7.0 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from mlflow==2.4.0) (8.0.4)\n",
      "Requirement already satisfied: databricks-cli<1,>=0.8.7 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from mlflow==2.4.0) (0.17.7)\n",
      "Requirement already satisfied: Flask<3 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from mlflow==2.4.0) (2.2.2)\n",
      "Requirement already satisfied: querystring-parser<2 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from mlflow==2.4.0) (1.2.4)\n",
      "Requirement already satisfied: cloudpickle<3 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from mlflow==2.4.0) (1.2.2)\n",
      "Requirement already satisfied: Jinja2<4,>=3.0 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from mlflow==2.4.0) (3.1.2)\n",
      "Requirement already satisfied: entrypoints<1 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from mlflow==2.4.0) (0.4)\n",
      "Requirement already satisfied: sqlparse<1,>=0.4.0 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from mlflow==2.4.0) (0.4.4)\n",
      "Requirement already satisfied: alembic!=1.10.0,<2 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from mlflow==2.4.0) (1.11.1)\n",
      "Requirement already satisfied: protobuf<5,>=3.12.0 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from mlflow==2.4.0) (4.23.1)\n",
      "Requirement already satisfied: pytz<2024 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from mlflow==2.4.0) (2022.7)\n",
      "Requirement already satisfied: importlib-metadata!=4.7.0,<7,>=3.7.0 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from mlflow==2.4.0) (4.11.3)\n",
      "Requirement already satisfied: packaging<24 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from mlflow==2.4.0) (21.3)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from bs4) (4.11.1)\n",
      "Requirement already satisfied: feedparser>=5.2.1 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from newspaper3k) (6.0.10)\n",
      "Requirement already satisfied: tldextract>=2.0.1 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from newspaper3k) (3.2.0)\n",
      "Requirement already satisfied: lxml>=3.6.0 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from newspaper3k) (4.9.1)\n",
      "Requirement already satisfied: Pillow>=3.3.0 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from newspaper3k) (9.4.0)\n",
      "Requirement already satisfied: feedfinder2>=0.0.4 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from newspaper3k) (0.0.4)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from newspaper3k) (2.8.2)\n",
      "Requirement already satisfied: jieba3k>=0.35.1 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from newspaper3k) (0.35.1)\n",
      "Requirement already satisfied: tinysegmenter==0.3 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from newspaper3k) (0.3)\n",
      "Requirement already satisfied: cssselect>=0.9.2 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from newspaper3k) (1.1.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.13.0 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from tensorflow) (2.13.0)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (0.4.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (2.3.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\alex\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (65.6.3)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (3.7.0)\n",
      "Requirement already satisfied: flatbuffers>=23.1.21 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (23.5.26)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.57.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (16.0.6)\n",
      "Requirement already satisfied: keras<2.14,>=2.13.1 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (2.13.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.4.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: tensorboard<2.14,>=2.13 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (2.13.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.14,>=2.13.0 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (2.13.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from transformers) (2022.7.9)\n",
      "Requirement already satisfied: filelock in c:\\users\\alex\\anaconda3\\lib\\site-packages (from transformers) (3.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.271) (2.0.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.271) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.271) (1.3.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.271) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.271) (1.9.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.271) (22.1.0)\n",
      "Requirement already satisfied: Mako in c:\\users\\alex\\anaconda3\\lib\\site-packages (from alembic!=1.10.0,<2->mlflow==2.4.0) (1.2.4)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from beautifulsoup4->bs4) (2.3.2.post1)\n",
      "Requirement already satisfied: colorama in c:\\users\\alex\\anaconda3\\lib\\site-packages (from click<9,>=7.0->mlflow==2.4.0) (0.4.6)\n",
      "Requirement already satisfied: urllib3>=1.26 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from clickhouse-connect>=0.5.7->chromadb==0.3.25) (1.26.14)\n",
      "Requirement already satisfied: certifi in c:\\users\\alex\\anaconda3\\lib\\site-packages (from clickhouse-connect>=0.5.7->chromadb==0.3.25) (2022.12.7)\n",
      "Requirement already satisfied: zstandard in c:\\users\\alex\\anaconda3\\lib\\site-packages (from clickhouse-connect>=0.5.7->chromadb==0.3.25) (0.19.0)\n",
      "Requirement already satisfied: lz4 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from clickhouse-connect>=0.5.7->chromadb==0.3.25) (3.1.3)\n",
      "Requirement already satisfied: pyjwt>=1.7.0 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from databricks-cli<1,>=0.8.7->mlflow==2.4.0) (2.4.0)\n",
      "Requirement already satisfied: tabulate>=0.7.7 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from databricks-cli<1,>=0.8.7->mlflow==2.4.0) (0.8.10)\n",
      "Requirement already satisfied: oauthlib>=3.1.0 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from databricks-cli<1,>=0.8.7->mlflow==2.4.0) (3.2.2)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain==0.0.271) (3.20.1)\n",
      "Requirement already satisfied: websocket-client>=0.32.0 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from docker<7,>=4.0.0->mlflow==2.4.0) (0.58.0)\n",
      "Requirement already satisfied: pywin32>=304 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from docker<7,>=4.0.0->mlflow==2.4.0) (305.1)\n",
      "Requirement already satisfied: starlette<0.28.0,>=0.27.0 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from fastapi>=0.85.1->chromadb==0.3.25) (0.27.0)\n",
      "Requirement already satisfied: sgmllib3k in c:\\users\\alex\\anaconda3\\lib\\site-packages (from feedparser>=5.2.1->newspaper3k) (1.0.0)\n",
      "Requirement already satisfied: itsdangerous>=2.0 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from Flask<3->mlflow==2.4.0) (2.0.1)\n",
      "Requirement already satisfied: Werkzeug>=2.2.2 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from Flask<3->mlflow==2.4.0) (2.2.2)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from gitpython<4,>=2.1.0->mlflow==2.4.0) (4.0.10)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from importlib-metadata!=4.7.0,<7,>=3.7.0->mlflow==2.4.0) (3.11.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from Jinja2<4,>=3.0->mlflow==2.4.0) (2.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from matplotlib<4->mlflow==2.4.0) (0.11.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from matplotlib<4->mlflow==2.4.0) (3.0.9)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from matplotlib<4->mlflow==2.4.0) (1.0.5)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from matplotlib<4->mlflow==2.4.0) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from matplotlib<4->mlflow==2.4.0) (1.4.4)\n",
      "Requirement already satisfied: joblib in c:\\users\\alex\\anaconda3\\lib\\site-packages (from nltk->sentence-transformers==2.2.2) (1.1.1)\n",
      "Requirement already satisfied: coloredlogs in c:\\users\\alex\\anaconda3\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb==0.3.25) (15.0.1)\n",
      "Requirement already satisfied: sympy in c:\\users\\alex\\anaconda3\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb==0.3.25) (1.11.1)\n",
      "Requirement already satisfied: backoff>=1.10.0 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from posthog>=2.4.0->chromadb==0.3.25) (2.2.1)\n",
      "Requirement already satisfied: monotonic>=1.5 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from posthog>=2.4.0->chromadb==0.3.25) (1.6)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain==0.0.271) (3.4)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from scikit-learn->sentence-transformers==2.2.2) (2.2.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain==0.0.271) (2.0.1)\n",
      "Requirement already satisfied: requests-file>=1.4 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from tldextract>=2.0.1->newspaper3k) (1.5.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\alex\\anaconda3\\lib\\site-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (2.8.4)\n",
      "Requirement already satisfied: h11>=0.8 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb==0.3.25) (0.14.0)\n",
      "Requirement already satisfied: httptools>=0.5.0 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb==0.3.25) (0.6.0)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb==0.3.25) (1.0.0)\n",
      "Requirement already satisfied: watchfiles>=0.13 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb==0.3.25) (0.19.0)\n",
      "Requirement already satisfied: websockets>=10.4 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb==0.3.25) (11.0.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.13.0->tensorflow) (0.38.4)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython<4,>=2.1.0->mlflow==2.4.0) (5.0.0)\n",
      "Requirement already satisfied: anyio<5,>=3.4.0 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from starlette<0.28.0,>=0.27.0->fastapi>=0.85.1->chromadb==0.3.25) (3.5.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.22.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (0.7.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb==0.3.25) (10.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from sympy->onnxruntime>=1.14.1->chromadb==0.3.25) (1.2.1)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from anyio<5,>=3.4.0->starlette<0.28.0,>=0.27.0->fastapi>=0.85.1->chromadb==0.3.25) (1.2.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (4.9)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (5.3.1)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: pyreadline3 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from humanfriendly>=9.1->coloredlogs->onnxruntime>=1.14.1->chromadb==0.3.25) (3.4.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (0.4.8)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -lflow (c:\\users\\alex\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -lflow (c:\\users\\alex\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -lflow (c:\\users\\alex\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -lflow (c:\\users\\alex\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -lflow (c:\\users\\alex\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -lflow (c:\\users\\alex\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "%pip install xmltodict bs4 langchain==0.0.271 typing-inspect==0.8.0 typing_extensions==4.5.0 newspaper3k sentence-transformers==2.2.2 chromadb==0.3.25 tensorflow transformers mlflow==2.4.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "79d784a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Alex\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter, RecursiveCharacterTextSplitter\n",
    "import pandas as pd\n",
    "import newspaper\n",
    "from newspaper import Article, Config\n",
    "import nltk\n",
    "\n",
    "nltk.download('punkt')\n",
    "\n",
    "from transformers import AutoTokenizer, TFAutoModel\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from langchain.document_loaders import DataFrameLoader\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain import HuggingFaceHub\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "\n",
    "import mlflow\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import glob\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d35235e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>text</th>\n",
       "      <th>keywords</th>\n",
       "      <th>summary</th>\n",
       "      <th>metadata</th>\n",
       "      <th>publishing_timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.infinitive.com/the-role-and-value-...</td>\n",
       "      <td>The Role and Value of Automation in Adopting N...</td>\n",
       "      <td>['Infinitive Difference Blog']</td>\n",
       "      <td>Mastering the data details\\n\\nAutomation in th...</td>\n",
       "      <td>['systems', 'product', 'media', 'migration', '...</td>\n",
       "      <td>That’s true of all of the essential components...</td>\n",
       "      <td>defaultdict(&lt;class 'dict'&gt;, {'viewport': 'widt...</td>\n",
       "      <td>2018-07-26 02:14:39+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.infinitive.com/leading-digital-tra...</td>\n",
       "      <td>Leading Digital Transformation: How Cultivatin...</td>\n",
       "      <td>['Infinitive Difference Blog']</td>\n",
       "      <td>In a 2002 Watson Wyatt study, high-trust organ...</td>\n",
       "      <td>['organizations', 'building', 'transformation'...</td>\n",
       "      <td>A Lack of Trust Hurts Your Business on Two Fro...</td>\n",
       "      <td>defaultdict(&lt;class 'dict'&gt;, {'viewport': 'widt...</td>\n",
       "      <td>2017-03-13 20:44:19+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.infinitive.com/use-big-data-effect...</td>\n",
       "      <td>How to Use Big Data Effectively: Data Strategy...</td>\n",
       "      <td>['Infinitive Difference Blog']</td>\n",
       "      <td>Gathering massive amounts of data is easier th...</td>\n",
       "      <td>['datadriven', 'business', 'strategy', 'volati...</td>\n",
       "      <td>As the panel of experts discussed, many compan...</td>\n",
       "      <td>defaultdict(&lt;class 'dict'&gt;, {'viewport': 'widt...</td>\n",
       "      <td>2016-06-06 15:37:24+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.infinitive.com/transformation-turd...</td>\n",
       "      <td>Transformation Turducken: 5 Tactics for Effect...</td>\n",
       "      <td>['Infinitive Difference Blog']</td>\n",
       "      <td>People: How the emotional intelligence of lead...</td>\n",
       "      <td>['plan', 'tactics', 'turducken', 'effective', ...</td>\n",
       "      <td>People: How the emotional intelligence of lead...</td>\n",
       "      <td>defaultdict(&lt;class 'dict'&gt;, {'viewport': 'widt...</td>\n",
       "      <td>2016-11-17 18:36:23+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.infinitive.com/how-big-data-transf...</td>\n",
       "      <td>How Big Data Transformed Sex, Drugs and Rock &amp;...</td>\n",
       "      <td>['Infinitive Difference Blog']</td>\n",
       "      <td>Behavioral data is the soul mate of the $2 bil...</td>\n",
       "      <td>['rock', 'music', 'guide', 'infographic', 'dat...</td>\n",
       "      <td>Behavioral data is the soul mate of the $2 bil...</td>\n",
       "      <td>defaultdict(&lt;class 'dict'&gt;, {'viewport': 'widt...</td>\n",
       "      <td>2015-09-03 16:46:10+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>https://www.infinitive.com/increase-speed-deli...</td>\n",
       "      <td>Increasing Speed, Delivery, and Innovation Wit...</td>\n",
       "      <td>['Evina Denenberg']</td>\n",
       "      <td>DevOps is a popular set of practices, tools, a...</td>\n",
       "      <td>['code', 'innovation', 'culture', 'change', 'd...</td>\n",
       "      <td>DevOps Requires Culture ChangeBuilding the rig...</td>\n",
       "      <td>defaultdict(&lt;class 'dict'&gt;, {'viewport': 'widt...</td>\n",
       "      <td>2023-07-31 19:18:12+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>https://www.infinitive.com/the-power-of-devops...</td>\n",
       "      <td>The Power of DevOps: Accelerating Business Gro...</td>\n",
       "      <td>['Evina Denenberg']</td>\n",
       "      <td>Enhanced Efficiency and Speed: In today’s digi...</td>\n",
       "      <td>['business', 'visibility', 'product', 'innovat...</td>\n",
       "      <td>Automated testing, continuous integration, and...</td>\n",
       "      <td>defaultdict(&lt;class 'dict'&gt;, {'viewport': 'widt...</td>\n",
       "      <td>2023-08-01 12:32:52+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>https://www.infinitive.com/aws-summit-nyc-reca...</td>\n",
       "      <td>AWS Summit NYC Recap – It’s All About AI</td>\n",
       "      <td>['Evina Denenberg']</td>\n",
       "      <td>Generative AI was at the forefront of discussi...</td>\n",
       "      <td>['ai', 'nyc', 'vector', 'summit', 'models', 'a...</td>\n",
       "      <td>AWS unveiled a series of exciting advancements...</td>\n",
       "      <td>defaultdict(&lt;class 'dict'&gt;, {'viewport': 'widt...</td>\n",
       "      <td>2023-08-02 15:05:47+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>https://www.infinitive.com/infinitive-announce...</td>\n",
       "      <td>Infinitive Announces Next Generation Suite of ...</td>\n",
       "      <td>['Evina Denenberg']</td>\n",
       "      <td>Infinitive’s comprehensive suite of solutions ...</td>\n",
       "      <td>['solutions', 'lifecycle', 'evaluate', 'suite'...</td>\n",
       "      <td>Infinitive’s comprehensive suite of solutions ...</td>\n",
       "      <td>defaultdict(&lt;class 'dict'&gt;, {'viewport': 'widt...</td>\n",
       "      <td>2023-08-14 13:20:42+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>https://www.infinitive.com/transforming-data-i...</td>\n",
       "      <td>Transforming Data Into Opportunities: Infiniti...</td>\n",
       "      <td>['Evina Denenberg']</td>\n",
       "      <td>Imagine a financial services firm once buried ...</td>\n",
       "      <td>['turned', 'infinitives', 'firm', 'transformin...</td>\n",
       "      <td>Imagine a financial services firm once buried ...</td>\n",
       "      <td>defaultdict(&lt;class 'dict'&gt;, {'viewport': 'widt...</td>\n",
       "      <td>2023-08-15 01:48:58+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>136 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   url  \\\n",
       "0    https://www.infinitive.com/the-role-and-value-...   \n",
       "1    https://www.infinitive.com/leading-digital-tra...   \n",
       "2    https://www.infinitive.com/use-big-data-effect...   \n",
       "3    https://www.infinitive.com/transformation-turd...   \n",
       "4    https://www.infinitive.com/how-big-data-transf...   \n",
       "..                                                 ...   \n",
       "131  https://www.infinitive.com/increase-speed-deli...   \n",
       "132  https://www.infinitive.com/the-power-of-devops...   \n",
       "133  https://www.infinitive.com/aws-summit-nyc-reca...   \n",
       "134  https://www.infinitive.com/infinitive-announce...   \n",
       "135  https://www.infinitive.com/transforming-data-i...   \n",
       "\n",
       "                                                 title  \\\n",
       "0    The Role and Value of Automation in Adopting N...   \n",
       "1    Leading Digital Transformation: How Cultivatin...   \n",
       "2    How to Use Big Data Effectively: Data Strategy...   \n",
       "3    Transformation Turducken: 5 Tactics for Effect...   \n",
       "4    How Big Data Transformed Sex, Drugs and Rock &...   \n",
       "..                                                 ...   \n",
       "131  Increasing Speed, Delivery, and Innovation Wit...   \n",
       "132  The Power of DevOps: Accelerating Business Gro...   \n",
       "133           AWS Summit NYC Recap – It’s All About AI   \n",
       "134  Infinitive Announces Next Generation Suite of ...   \n",
       "135  Transforming Data Into Opportunities: Infiniti...   \n",
       "\n",
       "                             author  \\\n",
       "0    ['Infinitive Difference Blog']   \n",
       "1    ['Infinitive Difference Blog']   \n",
       "2    ['Infinitive Difference Blog']   \n",
       "3    ['Infinitive Difference Blog']   \n",
       "4    ['Infinitive Difference Blog']   \n",
       "..                              ...   \n",
       "131             ['Evina Denenberg']   \n",
       "132             ['Evina Denenberg']   \n",
       "133             ['Evina Denenberg']   \n",
       "134             ['Evina Denenberg']   \n",
       "135             ['Evina Denenberg']   \n",
       "\n",
       "                                                  text  \\\n",
       "0    Mastering the data details\\n\\nAutomation in th...   \n",
       "1    In a 2002 Watson Wyatt study, high-trust organ...   \n",
       "2    Gathering massive amounts of data is easier th...   \n",
       "3    People: How the emotional intelligence of lead...   \n",
       "4    Behavioral data is the soul mate of the $2 bil...   \n",
       "..                                                 ...   \n",
       "131  DevOps is a popular set of practices, tools, a...   \n",
       "132  Enhanced Efficiency and Speed: In today’s digi...   \n",
       "133  Generative AI was at the forefront of discussi...   \n",
       "134  Infinitive’s comprehensive suite of solutions ...   \n",
       "135  Imagine a financial services firm once buried ...   \n",
       "\n",
       "                                              keywords  \\\n",
       "0    ['systems', 'product', 'media', 'migration', '...   \n",
       "1    ['organizations', 'building', 'transformation'...   \n",
       "2    ['datadriven', 'business', 'strategy', 'volati...   \n",
       "3    ['plan', 'tactics', 'turducken', 'effective', ...   \n",
       "4    ['rock', 'music', 'guide', 'infographic', 'dat...   \n",
       "..                                                 ...   \n",
       "131  ['code', 'innovation', 'culture', 'change', 'd...   \n",
       "132  ['business', 'visibility', 'product', 'innovat...   \n",
       "133  ['ai', 'nyc', 'vector', 'summit', 'models', 'a...   \n",
       "134  ['solutions', 'lifecycle', 'evaluate', 'suite'...   \n",
       "135  ['turned', 'infinitives', 'firm', 'transformin...   \n",
       "\n",
       "                                               summary  \\\n",
       "0    That’s true of all of the essential components...   \n",
       "1    A Lack of Trust Hurts Your Business on Two Fro...   \n",
       "2    As the panel of experts discussed, many compan...   \n",
       "3    People: How the emotional intelligence of lead...   \n",
       "4    Behavioral data is the soul mate of the $2 bil...   \n",
       "..                                                 ...   \n",
       "131  DevOps Requires Culture ChangeBuilding the rig...   \n",
       "132  Automated testing, continuous integration, and...   \n",
       "133  AWS unveiled a series of exciting advancements...   \n",
       "134  Infinitive’s comprehensive suite of solutions ...   \n",
       "135  Imagine a financial services firm once buried ...   \n",
       "\n",
       "                                              metadata  \\\n",
       "0    defaultdict(<class 'dict'>, {'viewport': 'widt...   \n",
       "1    defaultdict(<class 'dict'>, {'viewport': 'widt...   \n",
       "2    defaultdict(<class 'dict'>, {'viewport': 'widt...   \n",
       "3    defaultdict(<class 'dict'>, {'viewport': 'widt...   \n",
       "4    defaultdict(<class 'dict'>, {'viewport': 'widt...   \n",
       "..                                                 ...   \n",
       "131  defaultdict(<class 'dict'>, {'viewport': 'widt...   \n",
       "132  defaultdict(<class 'dict'>, {'viewport': 'widt...   \n",
       "133  defaultdict(<class 'dict'>, {'viewport': 'widt...   \n",
       "134  defaultdict(<class 'dict'>, {'viewport': 'widt...   \n",
       "135  defaultdict(<class 'dict'>, {'viewport': 'widt...   \n",
       "\n",
       "          publishing_timestamp  \n",
       "0    2018-07-26 02:14:39+00:00  \n",
       "1    2017-03-13 20:44:19+00:00  \n",
       "2    2016-06-06 15:37:24+00:00  \n",
       "3    2016-11-17 18:36:23+00:00  \n",
       "4    2015-09-03 16:46:10+00:00  \n",
       "..                         ...  \n",
       "131  2023-07-31 19:18:12+00:00  \n",
       "132  2023-08-01 12:32:52+00:00  \n",
       "133  2023-08-02 15:05:47+00:00  \n",
       "134  2023-08-14 13:20:42+00:00  \n",
       "135  2023-08-15 01:48:58+00:00  \n",
       "\n",
       "[136 rows x 8 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read the scraped data\n",
    "pandas_df = pd.read_csv('./inf_text.csv', index_col=0)\n",
    "pandas_df = pandas_df.drop('index', axis=1)\n",
    "pandas_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58a1fdf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in dataframe to be split\n",
    "documents = (\n",
    "  DataFrameLoader(\n",
    "    pandas_df,\n",
    "    page_content_column='text'\n",
    "    )\n",
    "    .load()\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc113889",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 3060, which is longer than the specified 512\n",
      "Created a chunk of size 3132, which is longer than the specified 512\n",
      "Created a chunk of size 782, which is longer than the specified 512\n",
      "Created a chunk of size 1328, which is longer than the specified 512\n",
      "Created a chunk of size 807, which is longer than the specified 512\n",
      "Created a chunk of size 906, which is longer than the specified 512\n",
      "Created a chunk of size 700, which is longer than the specified 512\n",
      "Created a chunk of size 553, which is longer than the specified 512\n",
      "Created a chunk of size 1160, which is longer than the specified 512\n",
      "Created a chunk of size 613, which is longer than the specified 512\n",
      "Created a chunk of size 659, which is longer than the specified 512\n",
      "Created a chunk of size 623, which is longer than the specified 512\n",
      "Created a chunk of size 515, which is longer than the specified 512\n",
      "Created a chunk of size 777, which is longer than the specified 512\n",
      "Created a chunk of size 541, which is longer than the specified 512\n",
      "Created a chunk of size 621, which is longer than the specified 512\n",
      "Created a chunk of size 809, which is longer than the specified 512\n",
      "Created a chunk of size 586, which is longer than the specified 512\n",
      "Created a chunk of size 613, which is longer than the specified 512\n",
      "Created a chunk of size 545, which is longer than the specified 512\n",
      "Created a chunk of size 536, which is longer than the specified 512\n",
      "Created a chunk of size 632, which is longer than the specified 512\n",
      "Created a chunk of size 550, which is longer than the specified 512\n",
      "Created a chunk of size 760, which is longer than the specified 512\n",
      "Created a chunk of size 680, which is longer than the specified 512\n",
      "Created a chunk of size 574, which is longer than the specified 512\n",
      "Created a chunk of size 720, which is longer than the specified 512\n",
      "Created a chunk of size 547, which is longer than the specified 512\n",
      "Created a chunk of size 613, which is longer than the specified 512\n",
      "Created a chunk of size 876, which is longer than the specified 512\n",
      "Created a chunk of size 534, which is longer than the specified 512\n",
      "Created a chunk of size 599, which is longer than the specified 512\n",
      "Created a chunk of size 632, which is longer than the specified 512\n",
      "Created a chunk of size 575, which is longer than the specified 512\n",
      "Created a chunk of size 718, which is longer than the specified 512\n",
      "Created a chunk of size 901, which is longer than the specified 512\n",
      "Created a chunk of size 678, which is longer than the specified 512\n",
      "Created a chunk of size 972, which is longer than the specified 512\n",
      "Created a chunk of size 1133, which is longer than the specified 512\n",
      "Created a chunk of size 820, which is longer than the specified 512\n",
      "Created a chunk of size 729, which is longer than the specified 512\n",
      "Created a chunk of size 868, which is longer than the specified 512\n",
      "Created a chunk of size 892, which is longer than the specified 512\n",
      "Created a chunk of size 783, which is longer than the specified 512\n",
      "Created a chunk of size 663, which is longer than the specified 512\n",
      "Created a chunk of size 731, which is longer than the specified 512\n",
      "Created a chunk of size 828, which is longer than the specified 512\n",
      "Created a chunk of size 677, which is longer than the specified 512\n",
      "Created a chunk of size 921, which is longer than the specified 512\n",
      "Created a chunk of size 623, which is longer than the specified 512\n",
      "Created a chunk of size 578, which is longer than the specified 512\n",
      "Created a chunk of size 596, which is longer than the specified 512\n",
      "Created a chunk of size 652, which is longer than the specified 512\n",
      "Created a chunk of size 798, which is longer than the specified 512\n",
      "Created a chunk of size 701, which is longer than the specified 512\n",
      "Created a chunk of size 637, which is longer than the specified 512\n",
      "Created a chunk of size 599, which is longer than the specified 512\n",
      "Created a chunk of size 883, which is longer than the specified 512\n",
      "Created a chunk of size 603, which is longer than the specified 512\n",
      "Created a chunk of size 580, which is longer than the specified 512\n",
      "Created a chunk of size 1165, which is longer than the specified 512\n",
      "Created a chunk of size 934, which is longer than the specified 512\n",
      "Created a chunk of size 997, which is longer than the specified 512\n",
      "Created a chunk of size 554, which is longer than the specified 512\n",
      "Created a chunk of size 877, which is longer than the specified 512\n",
      "Created a chunk of size 661, which is longer than the specified 512\n",
      "Created a chunk of size 550, which is longer than the specified 512\n",
      "Created a chunk of size 606, which is longer than the specified 512\n",
      "Created a chunk of size 557, which is longer than the specified 512\n",
      "Created a chunk of size 637, which is longer than the specified 512\n",
      "Created a chunk of size 650, which is longer than the specified 512\n",
      "Created a chunk of size 678, which is longer than the specified 512\n",
      "Created a chunk of size 875, which is longer than the specified 512\n",
      "Created a chunk of size 576, which is longer than the specified 512\n",
      "Created a chunk of size 538, which is longer than the specified 512\n",
      "Created a chunk of size 838, which is longer than the specified 512\n",
      "Created a chunk of size 558, which is longer than the specified 512\n",
      "Created a chunk of size 863, which is longer than the specified 512\n",
      "Created a chunk of size 563, which is longer than the specified 512\n",
      "Created a chunk of size 555, which is longer than the specified 512\n",
      "Created a chunk of size 583, which is longer than the specified 512\n",
      "Created a chunk of size 578, which is longer than the specified 512\n",
      "Created a chunk of size 2971, which is longer than the specified 512\n",
      "Created a chunk of size 545, which is longer than the specified 512\n",
      "Created a chunk of size 572, which is longer than the specified 512\n",
      "Created a chunk of size 720, which is longer than the specified 512\n",
      "Created a chunk of size 528, which is longer than the specified 512\n",
      "Created a chunk of size 571, which is longer than the specified 512\n",
      "Created a chunk of size 515, which is longer than the specified 512\n",
      "Created a chunk of size 584, which is longer than the specified 512\n",
      "Created a chunk of size 558, which is longer than the specified 512\n",
      "Created a chunk of size 673, which is longer than the specified 512\n",
      "Created a chunk of size 983, which is longer than the specified 512\n",
      "Created a chunk of size 557, which is longer than the specified 512\n",
      "Created a chunk of size 554, which is longer than the specified 512\n",
      "Created a chunk of size 715, which is longer than the specified 512\n",
      "Created a chunk of size 706, which is longer than the specified 512\n",
      "Created a chunk of size 728, which is longer than the specified 512\n",
      "Created a chunk of size 854, which is longer than the specified 512\n",
      "Created a chunk of size 1003, which is longer than the specified 512\n",
      "Created a chunk of size 1262, which is longer than the specified 512\n",
      "Created a chunk of size 748, which is longer than the specified 512\n",
      "Created a chunk of size 538, which is longer than the specified 512\n",
      "Created a chunk of size 3302, which is longer than the specified 512\n",
      "Created a chunk of size 547, which is longer than the specified 512\n",
      "Created a chunk of size 523, which is longer than the specified 512\n",
      "Created a chunk of size 685, which is longer than the specified 512\n",
      "Created a chunk of size 1439, which is longer than the specified 512\n",
      "Created a chunk of size 777, which is longer than the specified 512\n",
      "Created a chunk of size 583, which is longer than the specified 512\n",
      "Created a chunk of size 2831, which is longer than the specified 512\n",
      "Created a chunk of size 713, which is longer than the specified 512\n",
      "Created a chunk of size 761, which is longer than the specified 512\n",
      "Created a chunk of size 4193, which is longer than the specified 512\n",
      "Created a chunk of size 532, which is longer than the specified 512\n",
      "Created a chunk of size 579, which is longer than the specified 512\n",
      "Created a chunk of size 769, which is longer than the specified 512\n",
      "Created a chunk of size 952, which is longer than the specified 512\n",
      "Created a chunk of size 602, which is longer than the specified 512\n",
      "Created a chunk of size 536, which is longer than the specified 512\n",
      "Created a chunk of size 745, which is longer than the specified 512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 604, which is longer than the specified 512\n",
      "Created a chunk of size 618, which is longer than the specified 512\n",
      "Created a chunk of size 744, which is longer than the specified 512\n",
      "Created a chunk of size 587, which is longer than the specified 512\n",
      "Created a chunk of size 587, which is longer than the specified 512\n",
      "Created a chunk of size 555, which is longer than the specified 512\n",
      "Created a chunk of size 626, which is longer than the specified 512\n",
      "Created a chunk of size 681, which is longer than the specified 512\n",
      "Created a chunk of size 615, which is longer than the specified 512\n",
      "Created a chunk of size 920, which is longer than the specified 512\n",
      "Created a chunk of size 538, which is longer than the specified 512\n",
      "Created a chunk of size 533, which is longer than the specified 512\n",
      "Created a chunk of size 764, which is longer than the specified 512\n",
      "Created a chunk of size 585, which is longer than the specified 512\n",
      "Created a chunk of size 795, which is longer than the specified 512\n",
      "Created a chunk of size 772, which is longer than the specified 512\n",
      "Created a chunk of size 696, which is longer than the specified 512\n",
      "Created a chunk of size 578, which is longer than the specified 512\n",
      "Created a chunk of size 699, which is longer than the specified 512\n",
      "Created a chunk of size 842, which is longer than the specified 512\n",
      "Created a chunk of size 654, which is longer than the specified 512\n",
      "Created a chunk of size 689, which is longer than the specified 512\n",
      "Created a chunk of size 770, which is longer than the specified 512\n",
      "Created a chunk of size 707, which is longer than the specified 512\n",
      "Created a chunk of size 846, which is longer than the specified 512\n",
      "Created a chunk of size 902, which is longer than the specified 512\n",
      "Created a chunk of size 566, which is longer than the specified 512\n",
      "Created a chunk of size 743, which is longer than the specified 512\n",
      "Created a chunk of size 827, which is longer than the specified 512\n",
      "Created a chunk of size 735, which is longer than the specified 512\n",
      "Created a chunk of size 1466, which is longer than the specified 512\n",
      "Created a chunk of size 742, which is longer than the specified 512\n",
      "Created a chunk of size 586, which is longer than the specified 512\n",
      "Created a chunk of size 726, which is longer than the specified 512\n",
      "Created a chunk of size 725, which is longer than the specified 512\n",
      "Created a chunk of size 542, which is longer than the specified 512\n",
      "Created a chunk of size 566, which is longer than the specified 512\n",
      "Created a chunk of size 734, which is longer than the specified 512\n",
      "Created a chunk of size 778, which is longer than the specified 512\n",
      "Created a chunk of size 701, which is longer than the specified 512\n",
      "Created a chunk of size 519, which is longer than the specified 512\n",
      "Created a chunk of size 756, which is longer than the specified 512\n",
      "Created a chunk of size 674, which is longer than the specified 512\n",
      "Created a chunk of size 570, which is longer than the specified 512\n",
      "Created a chunk of size 778, which is longer than the specified 512\n",
      "Created a chunk of size 598, which is longer than the specified 512\n",
      "Created a chunk of size 642, which is longer than the specified 512\n",
      "Created a chunk of size 585, which is longer than the specified 512\n",
      "Created a chunk of size 604, which is longer than the specified 512\n",
      "Created a chunk of size 547, which is longer than the specified 512\n",
      "Created a chunk of size 1223, which is longer than the specified 512\n",
      "Created a chunk of size 755, which is longer than the specified 512\n",
      "Created a chunk of size 760, which is longer than the specified 512\n",
      "Created a chunk of size 568, which is longer than the specified 512\n",
      "Created a chunk of size 575, which is longer than the specified 512\n",
      "Created a chunk of size 710, which is longer than the specified 512\n",
      "Created a chunk of size 584, which is longer than the specified 512\n",
      "Created a chunk of size 700, which is longer than the specified 512\n",
      "Created a chunk of size 623, which is longer than the specified 512\n",
      "Created a chunk of size 538, which is longer than the specified 512\n",
      "Created a chunk of size 785, which is longer than the specified 512\n"
     ]
    }
   ],
   "source": [
    "text_splitter = CharacterTextSplitter(chunk_size=512, chunk_overlap=20, separator=\"\\n\", length_function=len)\n",
    "texts = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22ee24c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Mastering the data details\\nAutomation in the big picture\\nTo ensure data transformation and transfer issues are identified and addressed before migration to a new OMS\\nTo reduce the time it takes to import data after each test run, thereby facilitating a seamless migration into production environments', metadata={'url': 'https://www.infinitive.com/the-role-and-value-of-automation-in-adopting-new-ad-tech/', 'title': 'The Role and Value of Automation in Adopting New Ad Tech', 'author': \"['Infinitive Difference Blog']\", 'keywords': \"['systems', 'product', 'media', 'migration', 'data', 'ad', 'tools', 'automated', 'adopting', 'specific', 'tech', 'value', 'role', 'automation']\", 'summary': 'That’s true of all of the essential components of the ad tech stack, including order management systems (OMS), ad servers and billing software.\\nThat’s where automation tools come in.\\nAutomation can’t be viewed as a one-size-fits-all undertaking, because the nuances of ad tech environments vary considerably across media companies.\\nSimilarly, successful migrations require that templates and mapping models reflect specific product, fulfillment and billing requirements.\\nThe bottom line is that automation accelerates effective transitions for publishers adopting new ad tech.', 'metadata': \"defaultdict(<class 'dict'>, {'viewport': 'width=device-width, initial-scale=1', 'robots': 'index, follow, max-image-preview:large, max-snippet:-1, max-video-preview:-1', 'description': 'Given the continuous advancements in digital advertising technology and the steady pace of consolidation in the industry, it’s almost inevitable that', 'og': {'locale': 'en_US', 'type': 'article', 'title': 'The Role and Value of Automation in Adopting New Ad Tech', 'description': 'Given the continuous advancements in digital advertising technology and the steady pace of consolidation in the industry, it’s almost inevitable that', 'url': 'https://www.infinitive.com/the-role-and-value-of-automation-in-adopting-new-ad-tech/', 'site_name': 'Infinitive'}, 'article': {'publisher': 'https://www.facebook.com/Infinitive/', 'published_time': '2018-07-26T02:14:39+00:00', 'modified_time': '2023-04-07T14:29:04+00:00'}, 'author': 'Infinitive Difference Blog', 'twitter': {'card': 'summary_large_image', 'creator': '@infinitiveinc', 'site': '@infinitiveinc', 'label1': 'Written by', 'data1': 'Infinitive Difference Blog', 'label2': 'Est. reading time', 'data2': '5 minutes'}, 'generator': 'Elementor 3.15.2; features: e_dom_optimization, e_optimized_assets_loading, e_optimized_css_loading; settings: css_print_method-external, google_font-enabled, font_display-auto', 'msapplication-TileImage': 'https://www.infinitive.com/wp-content/uploads/2020/09/orange-bug.svg'})\", 'publishing_timestamp': '2018-07-26 02:14:39+00:00'}),\n",
       " Document(page_content='Given the continuous advancements in digital advertising technology and the steady pace of consolidation in the industry, it’s almost inevitable that publishers and media organizations will upgrade their existing or migrate to entirely new platforms and toolsets. That’s true of all of the essential components of the ad tech stack, including order management systems (OMS), ad servers and billing software. It’s no surprise, then, that publishers and media firms are looking for the most efficient and effective ways to handle upgrades and migrations from old to new systems. That’s where automation tools come in. Certainly, automating certain data extraction and migration processes can be highly beneficial. In fact, how you structure the data and how you use automation in data migration can make the difference between outstanding and mediocre ROI and determine whether or not you fulfill the business case for new or upgraded systems. But, as with so much else in the ad tech world, the devil is both in the details and in the big-picture context. Automation can’t be viewed as a one-size-fits-all undertaking, because the nuances of ad tech environments vary considerably across media companies. Business processes are different across media brands. So too are “secret sauce” product offerings and audience profiles. So what’s the role of automation? In our experience, automated tools should do the heavy lifting in migrating massive amounts of data off legacy technology and onto new systems and in testing that the data comes over accurately and appropriately. The benefits are faster timelines, fewer resources needed and lower error rates in migrating data.Automation alone doesn’t make for a perfect migration. Without careful mapping and modeling of data sets and product taxonomies and a detailed understanding of the differences between old and new systems, publishers are at risk of “garbage in, garbage out” scenarios and “apples-to-oranges” mismatches. Few systems allow for direct, 1-to-1 transfers of data. Line items and fields simply don’t match up exactly across, say, Operative OMS and Google DSM systems and ad servers. Thus, it’s necessary to understand how specific types of data are treated across systems. Similarly, successful migrations require that templates and mapping models reflect specific product, fulfillment and billing requirements. In other words, the use of automated tools should reflect business needs and objectives, rather than being defined by what automation can or can’t do.Thinking contextually about the key steps in a data migration clarifies the role and value of automation. For example, automation is a relatively straightforward process when extracting data. And transformation templates can help automate the process of preparing data to be loaded into a new OMS, ad server or other system. The load process is automated, too, of course. But these migration steps can – and should – be backed up by robust and iterative testing and validation processes within sandbox environments. Accelerated validations and systemic verification ensures data is migrating in line with business requirements and project objectives. But, again, automated tools must be designed and configured so they “know” what needs to be validated – not just that data came over, but that it was transferred to the right fields. Did quantitative data come over properly? Did open text and qualitative information end up in the right fields? In this way, automation helps reduce validation time frames. It also allows project teams to refine transformation logic based on the results of initial migrations to staging environments. The goals are simple:A series of automated test runs, with multiple validation points and other specific criteria for both quantitative and non-quantitative data, should be conducted prior to the production run. Again, this is how media companies can avoid the dreaded “garbage in, garbage out” and “apples-to-oranges” situations. So how do you make these adjustments? A combination of expertise and experience is essential. The key is to recognize how product taxonomies, account and campaign data, invoice line items, metrics, impressions, product definitions and attributes and other elements differ across the two systems. For example, FatTail allows for “flexible” ad sizes which means they can be entered/updated during line item creation, while other systems require you to define an ad size during product creation and cannot be altered during order entry. More broadly, if your data is of questionable quality in system A, you may want to make refinements before moving it to system B. No wonder that moving to a new OMS often leads publisher to consider rationalizing their product portfolios and otherwise enhancing their data. It’s best to know the common pitfalls and risks in moving from software A to software B. That way, automated tools and pre-configured templates can be adjusted to align or to solve for publishers’ specific and unique needs, product portfolios and IT environments. The challenges and complexities are directly proportionate to the size and structure of the companies. Aggregating campaigns and data across systems for a multi-brand media conglomerate is much more difficult than it is for standalone properties. The bottom line is that automation accelerates effective transitions for publishers adopting new ad tech. But the most effective automation is designed with both specific company and IT details and big-picture business objectives in mind.', metadata={'url': 'https://www.infinitive.com/the-role-and-value-of-automation-in-adopting-new-ad-tech/', 'title': 'The Role and Value of Automation in Adopting New Ad Tech', 'author': \"['Infinitive Difference Blog']\", 'keywords': \"['systems', 'product', 'media', 'migration', 'data', 'ad', 'tools', 'automated', 'adopting', 'specific', 'tech', 'value', 'role', 'automation']\", 'summary': 'That’s true of all of the essential components of the ad tech stack, including order management systems (OMS), ad servers and billing software.\\nThat’s where automation tools come in.\\nAutomation can’t be viewed as a one-size-fits-all undertaking, because the nuances of ad tech environments vary considerably across media companies.\\nSimilarly, successful migrations require that templates and mapping models reflect specific product, fulfillment and billing requirements.\\nThe bottom line is that automation accelerates effective transitions for publishers adopting new ad tech.', 'metadata': \"defaultdict(<class 'dict'>, {'viewport': 'width=device-width, initial-scale=1', 'robots': 'index, follow, max-image-preview:large, max-snippet:-1, max-video-preview:-1', 'description': 'Given the continuous advancements in digital advertising technology and the steady pace of consolidation in the industry, it’s almost inevitable that', 'og': {'locale': 'en_US', 'type': 'article', 'title': 'The Role and Value of Automation in Adopting New Ad Tech', 'description': 'Given the continuous advancements in digital advertising technology and the steady pace of consolidation in the industry, it’s almost inevitable that', 'url': 'https://www.infinitive.com/the-role-and-value-of-automation-in-adopting-new-ad-tech/', 'site_name': 'Infinitive'}, 'article': {'publisher': 'https://www.facebook.com/Infinitive/', 'published_time': '2018-07-26T02:14:39+00:00', 'modified_time': '2023-04-07T14:29:04+00:00'}, 'author': 'Infinitive Difference Blog', 'twitter': {'card': 'summary_large_image', 'creator': '@infinitiveinc', 'site': '@infinitiveinc', 'label1': 'Written by', 'data1': 'Infinitive Difference Blog', 'label2': 'Est. reading time', 'data2': '5 minutes'}, 'generator': 'Elementor 3.15.2; features: e_dom_optimization, e_optimized_assets_loading, e_optimized_css_loading; settings: css_print_method-external, google_font-enabled, font_display-auto', 'msapplication-TileImage': 'https://www.infinitive.com/wp-content/uploads/2020/09/orange-bug.svg'})\", 'publishing_timestamp': '2018-07-26 02:14:39+00:00'}),\n",
       " Document(page_content='In a 2002 Watson Wyatt study, high-trust organizations outperformed low-trust organizations in total return to shareholders by 286 percent. High-trust organizations also consistently create and deliver more value to their customers through accelerated growth, enhanced innovation, improved collaboration, stronger partnering, better execution and heightened loyalty.\\nA Lack of Trust Hurts Your Business on Two Fronts\\nWithout trust, your organization wastes time and money', metadata={'url': 'https://www.infinitive.com/leading-digital-transformation-cultivating-trust-enables-success/', 'title': 'Leading Digital Transformation: How Cultivating Trust Enables Success', 'author': \"['Infinitive Difference Blog']\", 'keywords': \"['organizations', 'building', 'transformation', 'success', 'lack', 'trust', 'leaders', 'project', 'cultivating', 'team', 'enables', 'leading', 'digital', 'communication']\", 'summary': 'A Lack of Trust Hurts Your Business on Two FrontsWithout trust, your organization wastes time and moneyA trust deficit establishes a success ceilingI recently came across some interesting survey results, which caused me to think about trust in the context of today’s digital transformation and change initiatives.\\nWithout trust, team communication may not be open enough for raising questions or concerns.\\nTransparent communication is also crucial to building trust more broadly across the organization, including among critical stakeholders who are not part of the everyday transformation team.\\nThis is especially true for large-scale digital transformation projects, which may include multiple levels or dimensions of simultaneous change.\\nAbout the Author:With something as difficult as digital transformation, organizations and leaders must take advantage of all available tools and resources and do everything they can to succeed.', 'metadata': \"defaultdict(<class 'dict'>, {'viewport': 'width=device-width, initial-scale=1', 'robots': 'index, follow, max-image-preview:large, max-snippet:-1, max-video-preview:-1', 'description': 'Learn how cultivating trust within your organization improves business outcomes and how to build trust to enable more successful digital transformation efforts', 'og': {'locale': 'en_US', 'type': 'article', 'title': 'Leading Digital Transformation: How Cultivating Trust Enables Success', 'description': 'Learn how cultivating trust within your organization improves business outcomes and how to build trust to enable more successful digital transformation efforts', 'url': 'https://www.infinitive.com/leading-digital-transformation-cultivating-trust-enables-success/', 'site_name': 'Infinitive'}, 'article': {'publisher': 'https://www.facebook.com/Infinitive/', 'published_time': '2017-03-13T20:44:19+00:00', 'modified_time': '2023-04-07T14:29:04+00:00'}, 'author': 'Infinitive Difference Blog', 'twitter': {'card': 'summary_large_image', 'creator': '@infinitiveinc', 'site': '@infinitiveinc', 'label1': 'Written by', 'data1': 'Infinitive Difference Blog', 'label2': 'Est. reading time', 'data2': '6 minutes'}, 'generator': 'Elementor 3.15.2; features: e_dom_optimization, e_optimized_assets_loading, e_optimized_css_loading; settings: css_print_method-external, google_font-enabled, font_display-auto', 'msapplication-TileImage': 'https://www.infinitive.com/wp-content/uploads/2020/09/orange-bug.svg'})\", 'publishing_timestamp': '2017-03-13 20:44:19+00:00'}),\n",
       " Document(page_content='A trust deficit establishes a success ceiling', metadata={'url': 'https://www.infinitive.com/leading-digital-transformation-cultivating-trust-enables-success/', 'title': 'Leading Digital Transformation: How Cultivating Trust Enables Success', 'author': \"['Infinitive Difference Blog']\", 'keywords': \"['organizations', 'building', 'transformation', 'success', 'lack', 'trust', 'leaders', 'project', 'cultivating', 'team', 'enables', 'leading', 'digital', 'communication']\", 'summary': 'A Lack of Trust Hurts Your Business on Two FrontsWithout trust, your organization wastes time and moneyA trust deficit establishes a success ceilingI recently came across some interesting survey results, which caused me to think about trust in the context of today’s digital transformation and change initiatives.\\nWithout trust, team communication may not be open enough for raising questions or concerns.\\nTransparent communication is also crucial to building trust more broadly across the organization, including among critical stakeholders who are not part of the everyday transformation team.\\nThis is especially true for large-scale digital transformation projects, which may include multiple levels or dimensions of simultaneous change.\\nAbout the Author:With something as difficult as digital transformation, organizations and leaders must take advantage of all available tools and resources and do everything they can to succeed.', 'metadata': \"defaultdict(<class 'dict'>, {'viewport': 'width=device-width, initial-scale=1', 'robots': 'index, follow, max-image-preview:large, max-snippet:-1, max-video-preview:-1', 'description': 'Learn how cultivating trust within your organization improves business outcomes and how to build trust to enable more successful digital transformation efforts', 'og': {'locale': 'en_US', 'type': 'article', 'title': 'Leading Digital Transformation: How Cultivating Trust Enables Success', 'description': 'Learn how cultivating trust within your organization improves business outcomes and how to build trust to enable more successful digital transformation efforts', 'url': 'https://www.infinitive.com/leading-digital-transformation-cultivating-trust-enables-success/', 'site_name': 'Infinitive'}, 'article': {'publisher': 'https://www.facebook.com/Infinitive/', 'published_time': '2017-03-13T20:44:19+00:00', 'modified_time': '2023-04-07T14:29:04+00:00'}, 'author': 'Infinitive Difference Blog', 'twitter': {'card': 'summary_large_image', 'creator': '@infinitiveinc', 'site': '@infinitiveinc', 'label1': 'Written by', 'data1': 'Infinitive Difference Blog', 'label2': 'Est. reading time', 'data2': '6 minutes'}, 'generator': 'Elementor 3.15.2; features: e_dom_optimization, e_optimized_assets_loading, e_optimized_css_loading; settings: css_print_method-external, google_font-enabled, font_display-auto', 'msapplication-TileImage': 'https://www.infinitive.com/wp-content/uploads/2020/09/orange-bug.svg'})\", 'publishing_timestamp': '2017-03-13 20:44:19+00:00'}),\n",
       " Document(page_content='I recently came across some interesting survey results, which caused me to think about trust in the context of today’s digital transformation and change initiatives. The following data from author Stephen Covey’s The Business Case for Trust is particularly enlightening:Though the survey is several years old, I believe trust is even more important and valuable now, given the increasing scope, velocity and necessity of change. Such a data point by itself represents a strong value proposition for building trust in any type of organization, though there are other compelling reasons why company leaders should emphasize trust. Covey has outlined his own business case for trust , which involves the ability to move more quickly and reduce hidden costs that often take the form of “low-trust organizational taxes,” a concept he has trademarked. Harvard Business Review has also examined the impact of trust on employee engagement and found that it’s a real difference maker. At high trust companies, people report “74% less stress,106% more energy at work, 50% higher productivity, 13% fewer sick days, 76% more engagement, 29% more satisfaction with their lives, [and] 40% less burnout” compared to their counterparts at low trust organizations. If you believe that worker or team engagement is helpful to project success, then trust should be part of your leadership toolkit.I’ve outlined some specific ways in which building trust builds business value. Likewise, a lack of trust undermines your organization. In my experience, lack of trust in organizations and teams threatens success in two major ways.Without trust, progress will be an uphill climb of negotiations, meetings and reluctance to take chances. Second-guessing people’s motives creates an environment in which safety and self-preservation take precedent over charging ahead or embracing necessary change. Such skepticism and resistance slows progress and stalls momentum. When there is no culture of trust, teams and organizations require the constant involvement of executive leadership as mediators or arbitrators, rather than efficiently leveraging them for vision-setting, decision-making and supportive communications, which are their natural roles. Additionally, within a transformation journey, failures and setbacks are difficult to overcome without trust. Blame-gaming may replace collective responsibility and the commitment to fix problems, learn from mistakes and move forward toward project goals. In my experience, trust helps projects move forward more quickly and purposefully and gets them back on track sooner when issues arise, as they inevitably do.As noted above, trust breeds collaboration and innovation. Without trust, the safe and risk-averse options will always win out. Teams without trust may unknowingly block paths and options that would provide higher ROI or greater customer experience. Who wants to put forward an unconventional, potentially controversial or “out of the box” idea if they don’t trust that their peers will receive that idea with open minds?', metadata={'url': 'https://www.infinitive.com/leading-digital-transformation-cultivating-trust-enables-success/', 'title': 'Leading Digital Transformation: How Cultivating Trust Enables Success', 'author': \"['Infinitive Difference Blog']\", 'keywords': \"['organizations', 'building', 'transformation', 'success', 'lack', 'trust', 'leaders', 'project', 'cultivating', 'team', 'enables', 'leading', 'digital', 'communication']\", 'summary': 'A Lack of Trust Hurts Your Business on Two FrontsWithout trust, your organization wastes time and moneyA trust deficit establishes a success ceilingI recently came across some interesting survey results, which caused me to think about trust in the context of today’s digital transformation and change initiatives.\\nWithout trust, team communication may not be open enough for raising questions or concerns.\\nTransparent communication is also crucial to building trust more broadly across the organization, including among critical stakeholders who are not part of the everyday transformation team.\\nThis is especially true for large-scale digital transformation projects, which may include multiple levels or dimensions of simultaneous change.\\nAbout the Author:With something as difficult as digital transformation, organizations and leaders must take advantage of all available tools and resources and do everything they can to succeed.', 'metadata': \"defaultdict(<class 'dict'>, {'viewport': 'width=device-width, initial-scale=1', 'robots': 'index, follow, max-image-preview:large, max-snippet:-1, max-video-preview:-1', 'description': 'Learn how cultivating trust within your organization improves business outcomes and how to build trust to enable more successful digital transformation efforts', 'og': {'locale': 'en_US', 'type': 'article', 'title': 'Leading Digital Transformation: How Cultivating Trust Enables Success', 'description': 'Learn how cultivating trust within your organization improves business outcomes and how to build trust to enable more successful digital transformation efforts', 'url': 'https://www.infinitive.com/leading-digital-transformation-cultivating-trust-enables-success/', 'site_name': 'Infinitive'}, 'article': {'publisher': 'https://www.facebook.com/Infinitive/', 'published_time': '2017-03-13T20:44:19+00:00', 'modified_time': '2023-04-07T14:29:04+00:00'}, 'author': 'Infinitive Difference Blog', 'twitter': {'card': 'summary_large_image', 'creator': '@infinitiveinc', 'site': '@infinitiveinc', 'label1': 'Written by', 'data1': 'Infinitive Difference Blog', 'label2': 'Est. reading time', 'data2': '6 minutes'}, 'generator': 'Elementor 3.15.2; features: e_dom_optimization, e_optimized_assets_loading, e_optimized_css_loading; settings: css_print_method-external, google_font-enabled, font_display-auto', 'msapplication-TileImage': 'https://www.infinitive.com/wp-content/uploads/2020/09/orange-bug.svg'})\", 'publishing_timestamp': '2017-03-13 20:44:19+00:00'})]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "584cda94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for deleting a directory\n",
    "def delete_dir(dir_path: str):\n",
    "        try:\n",
    "            shutil.rmtree(dir_path, ignore_errors=False)\n",
    "        except Exception as e:\n",
    "            print('Failed to delete %s. Reason: %s' % (dir_path, e))\n",
    "            print('If the file does not exist, this error can be treated as a warning.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e8378e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['HUGGINGFACEHUB_API_TOKEN'] = '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'\n",
    "embedding_model_path = './sentence_embedding_model_512'\n",
    "delete_dir(embedding_model_path) # delete existing dir so multiple runs won't cause issues\n",
    "\n",
    "original_model = SentenceTransformer('multi-qa-mpnet-base-dot-v1')\n",
    "original_model.save(embedding_model_path)\n",
    "\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=embedding_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4bde2a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# establish chromadb path, clear path if new notebook run\n",
    "chromadb_path = './search_chromadb_512'\n",
    "\n",
    "delete_dir(chromadb_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d317298d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "925"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define logic for embeddings storage\n",
    "vectordb = Chroma.from_documents(\n",
    "  documents=texts, \n",
    "  embedding=embedding_model, \n",
    "  persist_directory=chromadb_path\n",
    "  )\n",
    " \n",
    "# persist vector db to storage\n",
    "vectordb.persist()\n",
    "\n",
    "vectordb._collection.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b946ba52",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BlogSearchQA(mlflow.pyfunc.PythonModel):\n",
    " \n",
    "    \"\"\"BlogSearchQA is a class that extends the mlflow.pyfunc.PythonModel class\n",
    "    and is used to create a custom MLflow model for question answering using Transformers.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, repo_id, gen_config_dict=None, examples=\"\"):\n",
    "        \"\"\"\n",
    "        Initializes a new instance of the PyfuncTransformer class.\n",
    "\n",
    "        Args:\n",
    "            repo_id (str): The repo id of the pre-trained Transformer model to use.\n",
    "            gen_config_dict (dict): A dictionary of generation configuration parameters.\n",
    "            examples: examples for multi-shot prompting, prepended to the input.\n",
    "        \"\"\"\n",
    "        self.repo_id = repo_id\n",
    "        self.gen_config_dict = (\n",
    "            gen_config_dict if gen_config_dict is not None else {}\n",
    "        )\n",
    "        self.examples = examples\n",
    " \n",
    "      # define steps to load context\n",
    "    def load_context(self, context):\n",
    "\n",
    "        # import required libraries\n",
    "        import pandas as pd\n",
    "        from langchain.chains import RetrievalQA\n",
    "        from langchain.document_loaders import DataFrameLoader\n",
    "        from langchain.embeddings import HuggingFaceEmbeddings\n",
    "        from langchain.text_splitter import CharacterTextSplitter\n",
    "        from langchain.vectorstores import Chroma\n",
    "        from langchain.chains import LLMChain\n",
    "        from langchain import HuggingFaceHub\n",
    "        from langchain.prompts import PromptTemplate\n",
    "        import mlflow\n",
    "\n",
    "        # retrieve embedding model\n",
    "        embedding_model = HuggingFaceEmbeddings(model_name=context.artifacts['embedding_model'])\n",
    "\n",
    "        # retrieve vectordb contents\n",
    "        self._vectordb = Chroma(\n",
    "          persist_directory=context.artifacts['chromadb'],\n",
    "          embedding_function=embedding_model\n",
    "          )\n",
    "\n",
    "        self._vectordb.persist()\n",
    "\n",
    "      # define steps to generate results\n",
    "      # note: query_df expects only one query\n",
    "    \n",
    "    def predict(self, context, query):\n",
    "\n",
    "        # import required libraries\n",
    "        import pandas as pd\n",
    "        \n",
    "        # handle multiple queries\n",
    "        if isinstance(query, pd.DataFrame):\n",
    "            query = query.values.flatten().tolist()\n",
    "        elif not isinstance(query, list):\n",
    "            query = [query]\n",
    "\n",
    "        # perform search on embeddings\n",
    "        retriever = self._vectordb.as_retriever(search_type=\"similarity\", search_kwargs={\"k\":3})\n",
    "        os.environ['HUGGINGFACEHUB_API_TOKEN'] = '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'\n",
    "\n",
    "        # utilize prompt template to prevent the model from answering questions outside of context given\n",
    "        template = \"\"\"You are given the role of a question answering bot and will be given a question to answer and context to answer it with. If context is given and is relevant to the question, answer the question using the context. Otherwise, if context is not given, just say \"I couldn't find a post that answers this question. Please try another question.\". Do not answer the question if you are unsure. \n",
    "        Question: {question}\n",
    "        Context: {context}\n",
    "        Answer:\n",
    "        \"\"\"\n",
    "\n",
    "        PROMPT = PromptTemplate.from_template(template=template)\n",
    "        chain_type_kwargs = {\"prompt\": PROMPT}\n",
    "        llm = HuggingFaceHub(repo_id=self.repo_id, model_kwargs={\"temperature\":1e-10, \"max_length\":500}) \n",
    "        qa = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", retriever=retriever, return_source_documents=True, \n",
    "                                         chain_type_kwargs=chain_type_kwargs)\n",
    "        \n",
    "        # iterate over every query (one or many)\n",
    "        results = []\n",
    "        \n",
    "        for individual_query in query:\n",
    "            result = qa({\"query\": individual_query})\n",
    "            results.append(result['result'])\n",
    "        \n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b39148ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'embedding_model': './sentence_embedding_model_512', 'chromadb': './search_chromadb_512'}\n"
     ]
    }
   ],
   "source": [
    "artifacts = {\n",
    "  'embedding_model': embedding_model_path, \n",
    "  'chromadb': chromadb_path\n",
    "  }\n",
    " \n",
    "print(\n",
    "  artifacts\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9a3a0c0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'mlflow-env', 'channels': ['conda-forge'], 'dependencies': ['python=3.10.9', 'pip<=22.3.1', {'pip': ['mlflow', 'cloudpickle==1.2.2', 'pandas==1.5.3', 'langchain==0.0.271', 'chromadb==0.3.25', 'sentence_transformers==2.2.2', 'mlflow==2.4.0']}]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alex\\anaconda3\\lib\\site-packages\\_distutils_hack\\__init__.py:33: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "import langchain\n",
    "import chromadb\n",
    "import sentence_transformers\n",
    "import mlflow\n",
    "\n",
    "# get base environment configuration\n",
    "conda_env = mlflow.pyfunc.get_default_conda_env()\n",
    " \n",
    "# define packages required by model\n",
    "packages = [\n",
    "  f'pandas=={pandas.__version__}',\n",
    "  f'langchain=={langchain.__version__}',\n",
    "  f'chromadb=={chromadb.__version__}',\n",
    "  f'sentence_transformers=={sentence_transformers.__version__}',\n",
    "  f'mlflow=={mlflow.__version__}'\n",
    "  ]\n",
    " \n",
    "# add required packages to environment configuration\n",
    "conda_env['dependencies'][-1]['pip'] += packages\n",
    " \n",
    "print(\n",
    "  conda_env\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "00f21c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "bloom560 = BlogSearchQA(repo_id=\"bigscience/bloom-560m\")\n",
    "alpaca = BlogSearchQA(repo_id=\"declare-lab/flan-alpaca-large\")\n",
    "falcon = BlogSearchQA(repo_id=\"tiiuae/falcon-7b\")\n",
    "gpt2 = BlogSearchQA(repo_id=\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "03f411bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/08/24 13:55:47 INFO mlflow.tracking.fluent: Experiment with name 'compare_small_models' does not exist. Creating a new experiment.\n"
     ]
    }
   ],
   "source": [
    "mlflow.set_tracking_uri('http://localhost:5000')\n",
    "\n",
    "mlflow.set_experiment(experiment_name=\"compare_small_models\")\n",
    "run_ids = []\n",
    "artifact_paths = []\n",
    "model_names = [\"bloom560\", \"alpaca\", \"falcon\", \"gpt2\"]\n",
    "\n",
    "for model, name in zip([bloom560, alpaca, falcon, gpt2], model_names):\n",
    "    with mlflow.start_run(run_name=f\"log_model_{name}\"):\n",
    "        pyfunc_model = model\n",
    "        artifact_path = f\"models/{name}\"\n",
    "        mlflow.pyfunc.log_model(\n",
    "            artifact_path=artifact_path,\n",
    "            python_model=pyfunc_model,\n",
    "            input_example=\"Q: What is Universal Anaytics good at?\\nA:\",\n",
    "            conda_env=conda_env,\n",
    "            artifacts={'embedding_model': './sentence_embedding_model_512', 'chromadb': './recursive_search_chromadb'}\n",
    "        )\n",
    "        run_ids.append(mlflow.active_run().info.run_id)\n",
    "        artifact_paths.append(artifact_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1c4c252a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is universal analytics good at?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Who won the 2008 world series?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Who was the NHL #1 draft pick in 2023?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What is data migration?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How can I use first party data to create value?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             query\n",
       "0             What is universal analytics good at?\n",
       "1                   Who won the 2008 world series?\n",
       "2           Who was the NHL #1 draft pick in 2023?\n",
       "3                          What is data migration?\n",
       "4  How can I use first party data to create value?"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_df = pd.DataFrame(\n",
    "    {\n",
    "        \"query\": [\n",
    "            \"What is universal analytics good at?\",\n",
    "            \"Who won the 2008 world series?\",\n",
    "            \"Who was the NHL #1 draft pick in 2023?\",\n",
    "            \"What is data migration?\",\n",
    "            \"How can I use first party data to create value?\",\n",
    "        ]\n",
    "    }\n",
    ")\n",
    "eval_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e7949b56",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/08/24 13:58:20 INFO mlflow.models.evaluation.base: Evaluating the model with the default evaluator.\n",
      "2023/08/24 14:02:45 INFO mlflow.models.evaluation.base: Evaluating the model with the default evaluator.\n",
      "2023/08/24 14:04:04 INFO mlflow.models.evaluation.base: Evaluating the model with the default evaluator.\n",
      "2023/08/24 14:05:46 INFO mlflow.models.evaluation.base: Evaluating the model with the default evaluator.\n"
     ]
    }
   ],
   "source": [
    "for i in range(4):\n",
    "    with mlflow.start_run(run_id=run_ids[i]):  # reopen the run with the stored run ID\n",
    "        generated=mlflow.evaluate(\n",
    "            model=f\"runs:/{run_ids[i]}/{artifact_paths[i]}\",\n",
    "            model_type=\"text\",\n",
    "            data=eval_df,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "55d979b1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>outputs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is universal analytics good at?</td>\n",
       "      <td>Universal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Who won the 2008 world series?</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Who was the NHL #1 draft pick in 2023?</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What is data migration?</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How can I use first party data to create value?</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>What is universal analytics good at?</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Who won the 2008 world series?</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Who was the NHL #1 draft pick in 2023?</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>What is data migration?</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>How can I use first party data to create value?</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>What is universal analytics good at?</td>\n",
       "      <td>Universal Analytics was good at giving an over...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Who won the 2008 world series?</td>\n",
       "      <td>I couldn't find a post that answers this quest...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Who was the NHL #1 draft pick in 2023?</td>\n",
       "      <td>I couldn't find a post that answers this quest...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>What is data migration?</td>\n",
       "      <td>I couldn't find a post that answers this quest...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>How can I use first party data to create value?</td>\n",
       "      <td>I couldn't find a post that answers this quest...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>What is universal analytics good at?</td>\n",
       "      <td>Universal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Who won the 2008 world series?</td>\n",
       "      <td>1. The US team\\n         2. The UK team\\n    ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Who was the NHL #1 draft pick in 2023?</td>\n",
       "      <td>1. The NHL draft pick in 2023\\n         2. Th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>What is data migration?</td>\n",
       "      <td>Data migration is the process of migrating da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>How can I use first party data to create value?</td>\n",
       "      <td>1. Use the data to create value for your cust...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              query  \\\n",
       "0              What is universal analytics good at?   \n",
       "1                    Who won the 2008 world series?   \n",
       "2            Who was the NHL #1 draft pick in 2023?   \n",
       "3                           What is data migration?   \n",
       "4   How can I use first party data to create value?   \n",
       "5              What is universal analytics good at?   \n",
       "6                    Who won the 2008 world series?   \n",
       "7            Who was the NHL #1 draft pick in 2023?   \n",
       "8                           What is data migration?   \n",
       "9   How can I use first party data to create value?   \n",
       "10             What is universal analytics good at?   \n",
       "11                   Who won the 2008 world series?   \n",
       "12           Who was the NHL #1 draft pick in 2023?   \n",
       "13                          What is data migration?   \n",
       "14  How can I use first party data to create value?   \n",
       "15             What is universal analytics good at?   \n",
       "16                   Who won the 2008 world series?   \n",
       "17           Who was the NHL #1 draft pick in 2023?   \n",
       "18                          What is data migration?   \n",
       "19  How can I use first party data to create value?   \n",
       "\n",
       "                                              outputs  \n",
       "0                                           Universal  \n",
       "1                                                 ...  \n",
       "2                                                 ...  \n",
       "3                                                 ...  \n",
       "4                                                 ...  \n",
       "5                                                      \n",
       "6                                                      \n",
       "7                                                      \n",
       "8                                                      \n",
       "9                                                      \n",
       "10  Universal Analytics was good at giving an over...  \n",
       "11  I couldn't find a post that answers this quest...  \n",
       "12  I couldn't find a post that answers this quest...  \n",
       "13  I couldn't find a post that answers this quest...  \n",
       "14  I couldn't find a post that answers this quest...  \n",
       "15                                          Universal  \n",
       "16   1. The US team\\n         2. The UK team\\n    ...  \n",
       "17   1. The NHL draft pick in 2023\\n         2. Th...  \n",
       "18   Data migration is the process of migrating da...  \n",
       "19   1. Use the data to create value for your cust...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# retrieve output outside of mlflow UI\n",
    "mlflow.load_table(\"eval_results_table.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "629fe84c",
   "metadata": {},
   "source": [
    "# Try Different Splitting Technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5ba714fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to delete ./recursive_search_chromadb_512. Reason: [WinError 3] The system cannot find the path specified: './recursive_search_chromadb_512'\n",
      "If the file does not exist, this error can be treated as a warning.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1246"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_text_splitter = RecursiveCharacterTextSplitter(chunk_size=512, chunk_overlap=20, separators=[\"\\n\\n\", \"\\n\", \" \", \"\"], length_function=len)\n",
    "test_texts = test_text_splitter.split_documents(documents)\n",
    "\n",
    "embedding_model_path = './sentence_embedding_model_512'\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=embedding_model_path)\n",
    "\n",
    "recursive_chromadb_path = './recursive_search_chromadb_512'\n",
    "\n",
    "delete_dir(recursive_chromadb_path)\n",
    "\n",
    "vectordb = Chroma.from_documents(\n",
    "  documents=test_texts, \n",
    "  embedding=embedding_model, \n",
    "  persist_directory=recursive_chromadb_path\n",
    "  )\n",
    " \n",
    "# persist vector db to storage\n",
    "vectordb.persist()\n",
    "\n",
    "vectordb._collection.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f3bcfa",
   "metadata": {},
   "source": [
    "# Individually Troubleshooting LLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "66a33606",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for easily running LLMs with different configurations\n",
    "def run_configured_llm(embedding_model_path, chromadb_path, repo_id, model_kwargs: dict, chain_type, query: str, template):\n",
    "    '''\n",
    "    Args: embedding_model_path, chromadb_path, repo_id, model_kwargs: dict, query: str\n",
    "    '''\n",
    "    embedding_model = HuggingFaceEmbeddings(model_name=embedding_model_path)\n",
    "    docsearchCHROMA = Chroma(embedding_function=embedding_model, persist_directory=chromadb_path)\n",
    "\n",
    "    llm = HuggingFaceHub(repo_id=repo_id, model_kwargs=model_kwargs)\n",
    "\n",
    "    # utilize prompt to avoid answering question outside of context\n",
    "    PROMPT = PromptTemplate.from_template(template=template)\n",
    "    chain_type_kwargs = {\"prompt\": PROMPT}\n",
    "\n",
    "    # set up search and qa\n",
    "    retriever = docsearchCHROMA.as_retriever(search_type=\"similarity\", search_kwargs={\"k\":3})\n",
    "    \n",
    "    # create a chain to answer questions   \n",
    "    qa = RetrievalQA.from_chain_type(\n",
    "        llm=llm, chain_type=chain_type, retriever=retriever, return_source_documents=True, chain_type_kwargs=chain_type_kwargs)\n",
    "\n",
    "    result = qa({\"query\": query})\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c90c17ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "136\n",
      "1246\n",
      "1246\n"
     ]
    }
   ],
   "source": [
    "embedding_model_path='./search_embedding_model'\n",
    "chromadb_path='./search_chromadb'\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=embedding_model_path)\n",
    "\n",
    "print(Chroma(embedding_function=embedding_model, persist_directory=chromadb_path)._collection.count())\n",
    "print(Chroma(embedding_function=embedding_model, persist_directory=recursive_chromadb_path)._collection.count())\n",
    "\n",
    "\n",
    "print(vectordb._collection.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0aed5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Chain types: stuff, map_reduce, refine, map_rerank\n",
    "\n",
    "chroma db paths: './recursive_search_chromadb_512', './search_chromadb_512', './search_chromadb'\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3b62d3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"If context is given and is relevant to the question, answer the question using the context. Otherwise, if context is not given, just say \"I couldn't find a post that answers this question. Please try another question.\". Do not answer the question if you are unsure. \n",
    "    Question: {question}\n",
    "    Context: {context}\n",
    "    Answer:\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc6f0572",
   "metadata": {},
   "source": [
    "# Flan Alpaca Large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27875ed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "run_configured_llm(embedding_model_path='./sentence_embedding_model_512', chromadb_path='./search_chromadb_512', repo_id=\"declare-lab/flan-alpaca-large\", model_kwargs={\"temperature\":1e-10, \"max_length\":500}, chain_type='stuff', query='what is universal analytics good at?', template=template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "cec0bfab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'query': 'what is universal analytics good at?', 'result': 'Universal Analytics is good at tracking user time on page, but it is not good at understanding customer journey. GA4 is better at understanding customer journey, but it is not good at understanding customer interactions.', 'source_documents': [Document(page_content='Before I dive into the advantages and disadvantages of Universal Analytics and GA4, it is crucial to explain how these platforms are collecting the same data, but in very different ways. For example, in both platforms we are able to track average time on page, but the difference in how we track that data leads to some discrepancies. Universal Analytics tracked sessions based on the timeout session, which means a new session was triggered if an activity happened within the timeout session. GA4 evolved into a new concept called engaged sessions. Engaged sessions are based on user interactions or an event. In Universal Analytics, the user was tracked based on the unique identifier in their cookie, so if they went to your site on a different device they would be counted as a new user. Furthermore, GA4 also uses the unique identifier, but it can handle tracking cross-device and cross platform, allowing for a more accurate understanding of the user across multiple sessions and devices. In Universal Analytics it was simple, Google was tracking the individual user so they could see their average time on each page. In GA4 the only way to get average time on page is to divide total engaged time by engaged sessions. If a user exits your page before triggering an event, the time spent on the page may not be accurate. These are examples of how both platforms have average time on page, sessions, users, bounce rates, etc., but are being tracked differently.\\n\\nUniversal Analytics was very successful at giving an overall view of the user journey along with how customers arrived at your website. The long list of tracking data allowed you to set up various goals for each traffic source. Unfortunately, Universal Analytics fell short with privacy compliance and displaying the customer journey. In today’s sales funnel, a customer comes to your website many times across many devices, so Universal Analytics tracking all these visits as separate users is a huge disadvantage. GA4 is the exact opposite, it is a very comprehensive platform that allows you to track your customer across multiple devices and touchpoints, displaying a more accurate buyer funnel. In my opinion Universal Analytics was all about the user not giving a fully accurate representation of the buyer, whereas GA4 is all about the customer giving you data to better understand your customers journey. With Universal Analytics’ discontinuation right around the corner, companies will have to adapt to using Google Analytics 4’s capabilities.', metadata={'index': 119, 'url': 'https://www.infinitive.com/what-companies-should-expect-with-google-analytics-4/', 'title': 'What Companies Should Expect with Google Analytics 4 (GA4)', 'author': \"['Evina Denenberg']\", 'keywords': \"['sessions', 'customer', 'user', 'analytics', 'google', 'data', 'expect', 'engaged', 'ga4', 'universal', 'companies', 'tracking', 'page']\", 'summary': 'Universal Analytics tracked sessions based on the timeout session, which means a new session was triggered if an activity happened within the timeout session.\\nIn Universal Analytics it was simple, Google was tracking the individual user so they could see their average time on each page.\\nIn GA4 the only way to get average time on page is to divide total engaged time by engaged sessions.\\nUniversal Analytics was very successful at giving an overall view of the user journey along with how customers arrived at your website.\\nWith Universal Analytics’ discontinuation right around the corner, companies will have to adapt to using Google Analytics 4’s capabilities.', 'metadata': \"defaultdict(<class 'dict'>, {'viewport': 'width=device-width, initial-scale=1', 'robots': 'index, follow, max-image-preview:large, max-snippet:-1, max-video-preview:-1', 'description': 'As the termination of Universal Analytics slowly creeps up on July 1st, many companies will be forced to migrate from Universal Analytics to Google As the termination of Universal Analytics in July slowly creeps up on us, many companies will be forced to migrate from Universal Analytics to Google analytics 4 (GA4). The primary distinction between Universal Analytics and GA4 lies in their focus. Universal Analytics focused on sessions and pageviews, whereas GA4 is based on events and parameters. In GA4, an event allows you to measure specific interactions or occurrences on your website or app.', 'og': {'locale': 'en_US', 'type': 'article', 'title': 'What Companies Should Expect with Google Analytics 4 (GA4)', 'description': 'As the termination of Universal Analytics slowly creeps up on July 1st, many companies will be forced to migrate from Universal Analytics to Google As the termination of Universal Analytics in July slowly creeps up on us, many companies will be forced to migrate from Universal Analytics to Google analytics 4 (GA4). The primary distinction between Universal Analytics and GA4 lies in their focus. Universal Analytics focused on sessions and pageviews, whereas GA4 is based on events and parameters. In GA4, an event allows you to measure specific interactions or occurrences on your website or app.', 'url': 'https://www.infinitive.com/what-companies-should-expect-with-google-analytics-4/', 'site_name': 'Infinitive', 'image': {'identifier': 'https://www.infinitive.com/wp-content/uploads/2023/06/google-analytics-scaled.webp', 'width': 2560, 'height': 1444, 'type': 'image/jpeg'}}, 'article': {'publisher': 'https://www.facebook.com/Infinitive/', 'published_time': '2023-06-30T00:56:28+00:00'}, 'author': 'Evina Denenberg', 'twitter': {'card': 'summary_large_image', 'creator': '@infinitiveinc', 'site': '@infinitiveinc', 'label1': 'Written by', 'data1': 'Evina Denenberg', 'label2': 'Est. reading time', 'data2': '3 minutes'}, 'generator': 'Elementor 3.15.3; features: e_dom_optimization, e_optimized_assets_loading, e_optimized_css_loading; settings: css_print_method-external, google_font-enabled, font_display-auto', 'msapplication-TileImage': 'https://www.infinitive.com/wp-content/uploads/2020/09/orange-bug.svg'})\", 'publishing_timestamp': '2023-06-30 00:56:28+00:00'}), Document(page_content='Get More from Your Data with Graph Technology\\n\\nYour company is teeming with data, but do you have the tools to use it to its fullest extent?\\n\\nBusiness leaders are always looking for ways to leverage data to improve decision-making. Often, though, desired insights are out-of-reach due to a lack of context and inability to join islands of data in a meaningful way. Relational databases will only get you so far. Enter graph technology.\\n\\nA “graph” is a data structure that focuses on the logical relationships among data entities. Graph analytics (a.k.a., network analysis or link analysis) is used to explore these relationships to gain insights. Some well-known graph databases are Neo4j, AWS Neptune, Oracle Spatial, and Franz AllegroGraph, which are optimized to support this relationship structure and even have specialized query languages such as Gremlin, Cypher or SPARQL.\\n\\nPicture the data behind LinkedIn or any social network, which is perfectly suited for a graph structure. Users are connected to other users at many levels in a vast network. They also belong to groups, work for companies, and share posts – and these posts can be commented on, liked, celebrated, loved, etc. Each of these connections and actions between entities can be represented in a graph structure. Here’s a simplified example of what that structure might look like:\\n\\nWhy Graph Technology\\n\\nThe power of graph technology lies in its flexibility, intuitive structure, and unique relationship-based insights. Graph databases excel at linking data from disparate data sources, making it easy to create and expand a connected view of entities (known as nodes or vertices) such as customers, employees, products, transactions, etc. The relationships between entities (known as edges or links) typically reflect a subject>predicate>object structure. The relationships can also be directional as illustrated above (e.g., Bob Comments on a post).\\n\\nGraph analysis can provide unique insights by focusing on these relationships, looking at patterns and the nature of the connections. For example, Centrality is a core concept of graph analytics and is used to evaluate the relative importance of entities in the network. Centrality-based analysis considers how many connections an entity has, whether they are inbound vs. outbound relationships, or whether an entity is in the shortest path between two others.\\n\\nGraph analytics is so powerful that Gartner predicts a huge growth for the technology coming years. In a recent study, the research group predicted not only that data and analytics would become a core business function in 2021 but that graph technologies would be used 80% of the time by 2025, up from 10% in 2021.\\n\\nGraph Technology in Action\\n\\nGraph technology is a great choice for many different analytics use cases and can be utilized in virtually any industry or function. Below are just a few examples of the insights that can be gained:\\n\\nBusiness Continuity Management : Develop a holistic view of potential risks associated with the many dependencies that comprise a business continuity plan.\\n\\n: Develop a holistic view of potential risks associated with the many dependencies that comprise a business continuity plan. Fraud Detection : Explore suspicious patterns of activity or connect bad actors/fraudulent activity with other accounts, transactions and customers to provide real-time or forensic fraud alerts.\\n\\n: Explore suspicious patterns of activity or connect bad actors/fraudulent activity with other accounts, transactions and customers to provide real-time or forensic fraud alerts. Recommendation Engine & Product Recommendation System : Storing customers click-through data, purchase history, or their interests in a graph database allows a business to orchestrate campaigns to provide real-time recommendations to their consumers.\\n\\n: Storing customers click-through data, purchase history, or their interests in a graph database allows a business to orchestrate campaigns to provide real-time recommendations to their consumers. Application Resiliency Risk : Identify applications at risk due to factors such as tech incidents, change management control gaps, resiliency test results, audit finding or dependencies on applications with related risk factors.\\n\\n: Identify applications at risk due to factors such as tech incidents, change management control gaps, resiliency test results, audit finding or dependencies on applications with related risk factors. Human Resources : Build culture and improve retention by identifying internal influencers, skills, career paths, and other factors that lead to successful, effective, and happy employees.\\n\\nHow Infinitive can Help\\n\\nInfinitive consultants have the know-how and real-life experience to help you leverage graph technology and make the most of your data. For example, we recently worked a Top 10 Bank’s Audit group to develop proofs-of-concept to identify potential areas of risk related to access management and business continuity management.\\n\\nInfinitive can also take graph analysis to the next level by applying artificial intelligence to incorporate unstructured data in your graph, and machine learning to further refine application and model outputs.\\n\\nWhether you are exploring new customer insights, strengthening risk management capabilities, optimizing processes or whatever is important to you, Infinitive can turbo-charge your journey. From building proofs-of-concept to hardening an established model, Infinitive can help. Reach out today and let’s start the conversation.', metadata={'index': 24, 'url': 'https://www.infinitive.com/graph-technology/', 'title': 'Get More from Your Data with Graph Technology', 'author': \"['Evina Denenberg']\", 'keywords': \"['structure', 'risk', 'insights', 'relationships', 'data', 'technology', 'business', 'provide', 'graph', 'management']\", 'summary': 'Enter graph technology.\\nA “graph” is a data structure that focuses on the logical relationships among data entities.\\nHere’s a simplified example of what that structure might look like:Why Graph TechnologyThe power of graph technology lies in its flexibility, intuitive structure, and unique relationship-based insights.\\nGraph Technology in ActionGraph technology is a great choice for many different analytics use cases and can be utilized in virtually any industry or function.\\nHow Infinitive can HelpInfinitive consultants have the know-how and real-life experience to help you leverage graph technology and make the most of your data.', 'metadata': \"defaultdict(<class 'dict'>, {'viewport': 'width=device-width, initial-scale=1', 'robots': 'index, follow, max-image-preview:large, max-snippet:-1, max-video-preview:-1', 'description': 'Your company is teeming with data, but do you have the tools to use it to its fullest extent? Infinitive consultants have the know-how and real-life experience to help you leverage graph technology and make the most of your data.', 'og': {'locale': 'en_US', 'type': 'article', 'title': 'Get More from Your Data with Graph Technology', 'description': 'Your company is teeming with data, but do you have the tools to use it to its fullest extent? Infinitive consultants have the know-how and real-life experience to help you leverage graph technology and make the most of your data.', 'url': 'https://www.infinitive.com/graph-technology/', 'site_name': 'Infinitive', 'image': 'https://www.infinitive.com//wp-content/webpc-passthru.php?src=https://www.infinitive.com/wp-content/uploads/2021/06/graphdb.png&nocache=1'}, 'article': {'publisher': 'https://www.facebook.com/Infinitive/', 'published_time': '2021-06-17T17:29:13+00:00', 'modified_time': '2023-04-11T13:37:33+00:00'}, 'author': 'Evina Denenberg', 'twitter': {'card': 'summary_large_image', 'creator': '@infinitiveinc', 'site': '@infinitiveinc', 'label1': 'Written by', 'data1': 'Evina Denenberg', 'label2': 'Est. reading time', 'data2': '4 minutes'}, 'generator': 'Elementor 3.15.3; features: e_dom_optimization, e_optimized_assets_loading, e_optimized_css_loading; settings: css_print_method-external, google_font-enabled, font_display-auto', 'msapplication-TileImage': 'https://www.infinitive.com/wp-content/uploads/2020/09/orange-bug.svg'})\", 'publishing_timestamp': '2021-06-17 17:29:13+00:00'}), Document(page_content='Mastering the data details\\n\\nAutomation in the big picture\\n\\nTo ensure data transformation and transfer issues are identified and addressed before migration to a new OMS\\n\\nTo reduce the time it takes to import data after each test run, thereby facilitating a seamless migration into production environments\\n\\nGiven the continuous advancements in digital advertising technology and the steady pace of consolidation in the industry, it’s almost inevitable that publishers and media organizations will upgrade their existing or migrate to entirely new platforms and toolsets. That’s true of all of the essential components of the ad tech stack, including order management systems (OMS), ad servers and billing software. It’s no surprise, then, that publishers and media firms are looking for the most efficient and effective ways to handle upgrades and migrations from old to new systems. That’s where automation tools come in. Certainly, automating certain data extraction and migration processes can be highly beneficial. In fact, how you structure the data and how you use automation in data migration can make the difference between outstanding and mediocre ROI and determine whether or not you fulfill the business case for new or upgraded systems. But, as with so much else in the ad tech world, the devil is both in the details and in the big-picture context. Automation can’t be viewed as a one-size-fits-all undertaking, because the nuances of ad tech environments vary considerably across media companies. Business processes are different across media brands. So too are “secret sauce” product offerings and audience profiles. So what’s the role of automation? In our experience, automated tools should do the heavy lifting in migrating massive amounts of data off legacy technology and onto new systems and in testing that the data comes over accurately and appropriately. The benefits are faster timelines, fewer resources needed and lower error rates in migrating data.Automation alone doesn’t make for a perfect migration. Without careful mapping and modeling of data sets and product taxonomies and a detailed understanding of the differences between old and new systems, publishers are at risk of “garbage in, garbage out” scenarios and “apples-to-oranges” mismatches. Few systems allow for direct, 1-to-1 transfers of data. Line items and fields simply don’t match up exactly across, say, Operative OMS and Google DSM systems and ad servers. Thus, it’s necessary to understand how specific types of data are treated across systems. Similarly, successful migrations require that templates and mapping models reflect specific product, fulfillment and billing requirements. In other words, the use of automated tools should reflect business needs and objectives, rather than being defined by what automation can or can’t do.Thinking contextually about the key steps in a data migration clarifies the role and value of automation. For example, automation is a relatively straightforward process when extracting data. And transformation templates can help automate the process of preparing data to be loaded into a new OMS, ad server or other system. The load process is automated, too, of course. But these migration steps can – and should – be backed up by robust and iterative testing and validation processes within sandbox environments. Accelerated validations and systemic verification ensures data is migrating in line with business requirements and project objectives. But, again, automated tools must be designed and configured so they “know” what needs to be validated – not just that data came over, but that it was transferred to the right fields. Did quantitative data come over properly? Did open text and qualitative information end up in the right fields? In this way, automation helps reduce validation time frames. It also allows project teams to refine transformation logic based on the results of initial migrations to staging environments. The goals are simple:A series of automated test runs, with multiple validation points and other specific criteria for both quantitative and non-quantitative data, should be conducted prior to the production run. Again, this is how media companies can avoid the dreaded “garbage in, garbage out” and “apples-to-oranges” situations. So how do you make these adjustments? A combination of expertise and experience is essential. The key is to recognize how product taxonomies, account and campaign data, invoice line items, metrics, impressions, product definitions and attributes and other elements differ across the two systems. For example, FatTail allows for “flexible” ad sizes which means they can be entered/updated during line item creation, while other systems require you to define an ad size during product creation and cannot be altered during order entry. More broadly, if your data is of questionable quality in system A, you may want to make refinements before moving it to system B. No wonder that moving to a new OMS often leads publisher to consider rationalizing their product portfolios and otherwise enhancing their data. It’s best to know the common pitfalls and risks in moving from software A to software B. That way, automated tools and pre-configured templates can be adjusted to align or to solve for publishers’ specific and unique needs, product portfolios and IT environments. The challenges and complexities are directly proportionate to the size and structure of the companies. Aggregating campaigns and data across systems for a multi-brand media conglomerate is much more difficult than it is for standalone properties. The bottom line is that automation accelerates effective transitions for publishers adopting new ad tech. But the most effective automation is designed with both specific company and IT details and big-picture business objectives in mind.', metadata={'index': 0, 'url': 'https://www.infinitive.com/the-role-and-value-of-automation-in-adopting-new-ad-tech/', 'title': 'The Role and Value of Automation in Adopting New Ad Tech', 'author': \"['Infinitive Difference Blog']\", 'keywords': \"['tech', 'automation', 'media', 'adopting', 'role', 'systems', 'data', 'product', 'ad', 'automated', 'tools', 'specific', 'value', 'migration']\", 'summary': 'That’s true of all of the essential components of the ad tech stack, including order management systems (OMS), ad servers and billing software.\\nThat’s where automation tools come in.\\nAutomation can’t be viewed as a one-size-fits-all undertaking, because the nuances of ad tech environments vary considerably across media companies.\\nSimilarly, successful migrations require that templates and mapping models reflect specific product, fulfillment and billing requirements.\\nThe bottom line is that automation accelerates effective transitions for publishers adopting new ad tech.', 'metadata': \"defaultdict(<class 'dict'>, {'viewport': 'width=device-width, initial-scale=1', 'robots': 'index, follow, max-image-preview:large, max-snippet:-1, max-video-preview:-1', 'description': 'Given the continuous advancements in digital advertising technology and the steady pace of consolidation in the industry, it’s almost inevitable that', 'og': {'locale': 'en_US', 'type': 'article', 'title': 'The Role and Value of Automation in Adopting New Ad Tech', 'description': 'Given the continuous advancements in digital advertising technology and the steady pace of consolidation in the industry, it’s almost inevitable that', 'url': 'https://www.infinitive.com/the-role-and-value-of-automation-in-adopting-new-ad-tech/', 'site_name': 'Infinitive'}, 'article': {'publisher': 'https://www.facebook.com/Infinitive/', 'published_time': '2018-07-26T02:14:39+00:00', 'modified_time': '2023-04-07T14:29:04+00:00'}, 'author': 'Infinitive Difference Blog', 'twitter': {'card': 'summary_large_image', 'creator': '@infinitiveinc', 'site': '@infinitiveinc', 'label1': 'Written by', 'data1': 'Infinitive Difference Blog', 'label2': 'Est. reading time', 'data2': '5 minutes'}, 'generator': 'Elementor 3.15.3; features: e_dom_optimization, e_optimized_assets_loading, e_optimized_css_loading; settings: css_print_method-external, google_font-enabled, font_display-auto', 'msapplication-TileImage': 'https://www.infinitive.com/wp-content/uploads/2020/09/orange-bug.svg'})\", 'publishing_timestamp': '2018-07-26 02:14:39+00:00'})]}\n"
     ]
    }
   ],
   "source": [
    "run_configured_llm(embedding_model_path='./search_embedding_model', chromadb_path='./search_chromadb', repo_id=\"declare-lab/flan-alpaca-large\", model_kwargs={\"temperature\":1e-10, \"max_length\":500}, chain_type='stuff', query='what is universal analytics good at?', template=template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4a3fccdf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'query': 'what is universal analytics good at?', 'result': 'Universal Analytics is good at giving an overall view of the user journey along with how customers arrived at your website. The long list of tracking data allowed you to set up various goals for each traffic source. Unfortunately, Universal Analytics fell short with privacy compliance and displaying the customer journey. In today’s sales funnel, a customer comes to your website many times across many devices, so Universal Analytics tracking all these visits as separate users is a huge get you the 360 consumer view and answers you need to fully leverage your 1st party data.', 'source_documents': [Document(page_content='Universal Analytics was very successful at giving an overall view of the user journey along with how customers arrived at your website. The long list of tracking data allowed you to set up various goals for each traffic source. Unfortunately, Universal Analytics fell short with privacy compliance and displaying the customer journey. In today’s sales funnel, a customer comes to your website many times across many devices, so Universal Analytics tracking all these visits as separate users is a huge', metadata={'url': 'https://www.infinitive.com/what-companies-should-expect-with-google-analytics-4/', 'title': 'What Companies Should Expect with Google Analytics 4 (GA4)', 'author': \"['Evina Denenberg']\", 'keywords': \"['ga4', 'analytics', 'engaged', 'google', 'data', 'expect', 'companies', 'user', 'sessions', 'tracking', 'universal', 'customer', 'page']\", 'summary': 'Universal Analytics tracked sessions based on the timeout session, which means a new session was triggered if an activity happened within the timeout session.\\nIn Universal Analytics it was simple, Google was tracking the individual user so they could see their average time on each page.\\nIn GA4 the only way to get average time on page is to divide total engaged time by engaged sessions.\\nUniversal Analytics was very successful at giving an overall view of the user journey along with how customers arrived at your website.\\nWith Universal Analytics’ discontinuation right around the corner, companies will have to adapt to using Google Analytics 4’s capabilities.', 'metadata': \"defaultdict(<class 'dict'>, {'viewport': 'width=device-width, initial-scale=1', 'robots': 'index, follow, max-image-preview:large, max-snippet:-1, max-video-preview:-1', 'description': 'As the termination of Universal Analytics slowly creeps up on July 1st, many companies will be forced to migrate from Universal Analytics to Google As the termination of Universal Analytics in July slowly creeps up on us, many companies will be forced to migrate from Universal Analytics to Google analytics 4 (GA4). The primary distinction between Universal Analytics and GA4 lies in their focus. Universal Analytics focused on sessions and pageviews, whereas GA4 is based on events and parameters. In GA4, an event allows you to measure specific interactions or occurrences on your website or app.', 'og': {'locale': 'en_US', 'type': 'article', 'title': 'What Companies Should Expect with Google Analytics 4 (GA4)', 'description': 'As the termination of Universal Analytics slowly creeps up on July 1st, many companies will be forced to migrate from Universal Analytics to Google As the termination of Universal Analytics in July slowly creeps up on us, many companies will be forced to migrate from Universal Analytics to Google analytics 4 (GA4). The primary distinction between Universal Analytics and GA4 lies in their focus. Universal Analytics focused on sessions and pageviews, whereas GA4 is based on events and parameters. In GA4, an event allows you to measure specific interactions or occurrences on your website or app.', 'url': 'https://www.infinitive.com/what-companies-should-expect-with-google-analytics-4/', 'site_name': 'Infinitive', 'image': {'identifier': 'https://www.infinitive.com/wp-content/uploads/2023/06/google-analytics-scaled.webp', 'width': 2560, 'height': 1444, 'type': 'image/jpeg'}}, 'article': {'publisher': 'https://www.facebook.com/Infinitive/', 'published_time': '2023-06-30T00:56:28+00:00'}, 'author': 'Evina Denenberg', 'twitter': {'card': 'summary_large_image', 'creator': '@infinitiveinc', 'site': '@infinitiveinc', 'label1': 'Written by', 'data1': 'Evina Denenberg', 'label2': 'Est. reading time', 'data2': '3 minutes'}, 'generator': 'Elementor 3.15.2; features: e_dom_optimization, e_optimized_assets_loading, e_optimized_css_loading; settings: css_print_method-external, google_font-enabled, font_display-auto', 'msapplication-TileImage': 'https://www.infinitive.com/wp-content/uploads/2020/09/orange-bug.svg'})\", 'publishing_timestamp': '2023-06-30 00:56:28+00:00'}), Document(page_content='get you the 360 consumer view and answers you need to fully leverage your 1st party data.', metadata={'url': 'https://www.infinitive.com/optimize-1st-party-data-collect/', 'title': 'How to Optimize Your 1st Party Data - Step 1: Collect', 'author': \"['Evina Denenberg']\", 'keywords': \"['view', 'collection', 'business', 'collect', 'data', 'consumer', 'optimize', 'companies', 'tools', 'step', 'need', 'party', '1st']\", 'summary': 'In our first blog of the Consumer Intelligence series (1st Party Data, Clean Rooms, and Privacy — Why it’s so Hot), we emphasized the importance of your 1st party data and how Infinitive helps companies get the value out of their data by a 3-step process – Collect, Protect, and Connect.\\nWhat’s Your Data StrategyThe introduction of Direct-to-Consumer services and the collection of 1st party data significantly changed the media landscape by opening new data sources.\\nAlthough benefits of 1st party data for Publishers are well known, many of them are not yet truly leveraging their data’s full potential.\\nData Science and MLYour data collection process and storage must enable your Data Science teams to easily access and consume your unstructured, semi-structured, and structured data.\\nWhile it allows you to collect, store and govern your data, it provides features to your Data Gurus to innovate, implement predictive models, and extract the maximum benefit out of your 1st party data.', 'metadata': \"defaultdict(<class 'dict'>, {'viewport': 'width=device-width, initial-scale=1', 'robots': 'index, follow, max-image-preview:large, max-snippet:-1, max-video-preview:-1', 'description': 'Monetization Insights: Utilizes AI/ML and logfile analysis to automate ad break recommendation and insertion to create monetization solutions. Our solution also identifies dollars left on the table from missed ad opportunities.', 'og': {'locale': 'en_US', 'type': 'article', 'title': 'How to Optimize Your 1st Party Data - Step 1: Collect', 'description': 'Monetization Insights: Utilizes AI/ML and logfile analysis to automate ad break recommendation and insertion to create monetization solutions. Our solution also identifies dollars left on the table from missed ad opportunities.', 'url': 'https://www.infinitive.com/optimize-1st-party-data-collect/', 'site_name': 'Infinitive', 'image': {'identifier': 'https://www.infinitive.com/wp-content/uploads/2022/06/GettyImages-1209831813-scaled.webp', 'width': 2560, 'height': 1440, 'type': 'image/jpeg'}}, 'article': {'publisher': 'https://www.facebook.com/Infinitive/', 'published_time': '2022-06-30T14:19:59+00:00', 'modified_time': '2023-07-25T13:18:01+00:00'}, 'author': 'Evina Denenberg', 'twitter': {'card': 'summary_large_image', 'creator': '@infinitiveinc', 'site': '@infinitiveinc', 'label1': 'Written by', 'data1': 'Evina Denenberg', 'label2': 'Est. reading time', 'data2': '6 minutes'}, 'generator': 'Elementor 3.15.2; features: e_dom_optimization, e_optimized_assets_loading, e_optimized_css_loading; settings: css_print_method-external, google_font-enabled, font_display-auto', 'msapplication-TileImage': 'https://www.infinitive.com/wp-content/uploads/2020/09/orange-bug.svg'})\", 'publishing_timestamp': '2022-06-30 14:19:59+00:00'}), Document(page_content='Before I dive into the advantages and disadvantages of Universal Analytics and GA4, it is crucial to explain how these platforms are collecting the same data, but in very different ways. For example, in both platforms we are able to track average time on page, but the difference in how we track that data leads to some discrepancies. Universal Analytics tracked sessions based on the timeout session, which means a new session was triggered if an activity happened within the timeout session. GA4 evolved into a', metadata={'url': 'https://www.infinitive.com/what-companies-should-expect-with-google-analytics-4/', 'title': 'What Companies Should Expect with Google Analytics 4 (GA4)', 'author': \"['Evina Denenberg']\", 'keywords': \"['ga4', 'analytics', 'engaged', 'google', 'data', 'expect', 'companies', 'user', 'sessions', 'tracking', 'universal', 'customer', 'page']\", 'summary': 'Universal Analytics tracked sessions based on the timeout session, which means a new session was triggered if an activity happened within the timeout session.\\nIn Universal Analytics it was simple, Google was tracking the individual user so they could see their average time on each page.\\nIn GA4 the only way to get average time on page is to divide total engaged time by engaged sessions.\\nUniversal Analytics was very successful at giving an overall view of the user journey along with how customers arrived at your website.\\nWith Universal Analytics’ discontinuation right around the corner, companies will have to adapt to using Google Analytics 4’s capabilities.', 'metadata': \"defaultdict(<class 'dict'>, {'viewport': 'width=device-width, initial-scale=1', 'robots': 'index, follow, max-image-preview:large, max-snippet:-1, max-video-preview:-1', 'description': 'As the termination of Universal Analytics slowly creeps up on July 1st, many companies will be forced to migrate from Universal Analytics to Google As the termination of Universal Analytics in July slowly creeps up on us, many companies will be forced to migrate from Universal Analytics to Google analytics 4 (GA4). The primary distinction between Universal Analytics and GA4 lies in their focus. Universal Analytics focused on sessions and pageviews, whereas GA4 is based on events and parameters. In GA4, an event allows you to measure specific interactions or occurrences on your website or app.', 'og': {'locale': 'en_US', 'type': 'article', 'title': 'What Companies Should Expect with Google Analytics 4 (GA4)', 'description': 'As the termination of Universal Analytics slowly creeps up on July 1st, many companies will be forced to migrate from Universal Analytics to Google As the termination of Universal Analytics in July slowly creeps up on us, many companies will be forced to migrate from Universal Analytics to Google analytics 4 (GA4). The primary distinction between Universal Analytics and GA4 lies in their focus. Universal Analytics focused on sessions and pageviews, whereas GA4 is based on events and parameters. In GA4, an event allows you to measure specific interactions or occurrences on your website or app.', 'url': 'https://www.infinitive.com/what-companies-should-expect-with-google-analytics-4/', 'site_name': 'Infinitive', 'image': {'identifier': 'https://www.infinitive.com/wp-content/uploads/2023/06/google-analytics-scaled.webp', 'width': 2560, 'height': 1444, 'type': 'image/jpeg'}}, 'article': {'publisher': 'https://www.facebook.com/Infinitive/', 'published_time': '2023-06-30T00:56:28+00:00'}, 'author': 'Evina Denenberg', 'twitter': {'card': 'summary_large_image', 'creator': '@infinitiveinc', 'site': '@infinitiveinc', 'label1': 'Written by', 'data1': 'Evina Denenberg', 'label2': 'Est. reading time', 'data2': '3 minutes'}, 'generator': 'Elementor 3.15.2; features: e_dom_optimization, e_optimized_assets_loading, e_optimized_css_loading; settings: css_print_method-external, google_font-enabled, font_display-auto', 'msapplication-TileImage': 'https://www.infinitive.com/wp-content/uploads/2020/09/orange-bug.svg'})\", 'publishing_timestamp': '2023-06-30 00:56:28+00:00'})]}\n"
     ]
    }
   ],
   "source": [
    "run_configured_llm(embedding_model_path='./search_embedding_model', chromadb_path= './recursive_search_chromadb_512', repo_id=\"declare-lab/flan-alpaca-large\", model_kwargs={\"temperature\":1e-10, \"max_length\":500}, chain_type='stuff', query='what is universal analytics good at?', template=template)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "053ee52f",
   "metadata": {},
   "source": [
    "# bloom560"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "bfb9a45e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'query': 'what is universal analytics good at?', 'result': ' Data', 'source_documents': [Document(page_content='Universal Analytics was very successful at giving an overall view of the user journey along with how customers arrived at your website. The long list of tracking data allowed you to set up various goals for each traffic source. Unfortunately, Universal Analytics fell short with privacy compliance and displaying the customer journey. In today’s sales funnel, a customer comes to your website many times across many devices, so Universal Analytics tracking all these visits as separate users is a huge disadvantage. GA4 is the exact opposite, it is a very comprehensive platform that allows you to track your customer across multiple devices and touchpoints, displaying a more accurate buyer funnel. In my opinion Universal Analytics was all about the user not giving a fully accurate representation of the buyer, whereas GA4 is all about the customer giving you data to better understand your customers journey. With Universal Analytics’ discontinuation right around the corner, companies will have to adapt to using Google Analytics 4’s capabilities.', metadata={'url': 'https://www.infinitive.com/what-companies-should-expect-with-google-analytics-4/', 'title': 'What Companies Should Expect with Google Analytics 4 (GA4)', 'author': \"['Evina Denenberg']\", 'keywords': \"['ga4', 'analytics', 'engaged', 'google', 'data', 'expect', 'companies', 'user', 'sessions', 'tracking', 'universal', 'customer', 'page']\", 'summary': 'Universal Analytics tracked sessions based on the timeout session, which means a new session was triggered if an activity happened within the timeout session.\\nIn Universal Analytics it was simple, Google was tracking the individual user so they could see their average time on each page.\\nIn GA4 the only way to get average time on page is to divide total engaged time by engaged sessions.\\nUniversal Analytics was very successful at giving an overall view of the user journey along with how customers arrived at your website.\\nWith Universal Analytics’ discontinuation right around the corner, companies will have to adapt to using Google Analytics 4’s capabilities.', 'metadata': \"defaultdict(<class 'dict'>, {'viewport': 'width=device-width, initial-scale=1', 'robots': 'index, follow, max-image-preview:large, max-snippet:-1, max-video-preview:-1', 'description': 'As the termination of Universal Analytics slowly creeps up on July 1st, many companies will be forced to migrate from Universal Analytics to Google As the termination of Universal Analytics in July slowly creeps up on us, many companies will be forced to migrate from Universal Analytics to Google analytics 4 (GA4). The primary distinction between Universal Analytics and GA4 lies in their focus. Universal Analytics focused on sessions and pageviews, whereas GA4 is based on events and parameters. In GA4, an event allows you to measure specific interactions or occurrences on your website or app.', 'og': {'locale': 'en_US', 'type': 'article', 'title': 'What Companies Should Expect with Google Analytics 4 (GA4)', 'description': 'As the termination of Universal Analytics slowly creeps up on July 1st, many companies will be forced to migrate from Universal Analytics to Google As the termination of Universal Analytics in July slowly creeps up on us, many companies will be forced to migrate from Universal Analytics to Google analytics 4 (GA4). The primary distinction between Universal Analytics and GA4 lies in their focus. Universal Analytics focused on sessions and pageviews, whereas GA4 is based on events and parameters. In GA4, an event allows you to measure specific interactions or occurrences on your website or app.', 'url': 'https://www.infinitive.com/what-companies-should-expect-with-google-analytics-4/', 'site_name': 'Infinitive', 'image': {'identifier': 'https://www.infinitive.com/wp-content/uploads/2023/06/google-analytics-scaled.webp', 'width': 2560, 'height': 1444, 'type': 'image/jpeg'}}, 'article': {'publisher': 'https://www.facebook.com/Infinitive/', 'published_time': '2023-06-30T00:56:28+00:00'}, 'author': 'Evina Denenberg', 'twitter': {'card': 'summary_large_image', 'creator': '@infinitiveinc', 'site': '@infinitiveinc', 'label1': 'Written by', 'data1': 'Evina Denenberg', 'label2': 'Est. reading time', 'data2': '3 minutes'}, 'generator': 'Elementor 3.15.2; features: e_dom_optimization, e_optimized_assets_loading, e_optimized_css_loading; settings: css_print_method-external, google_font-enabled, font_display-auto', 'msapplication-TileImage': 'https://www.infinitive.com/wp-content/uploads/2020/09/orange-bug.svg'})\", 'publishing_timestamp': '2023-06-30 00:56:28+00:00'}), Document(page_content='Before I dive into the advantages and disadvantages of Universal Analytics and GA4, it is crucial to explain how these platforms are collecting the same data, but in very different ways. For example, in both platforms we are able to track average time on page, but the difference in how we track that data leads to some discrepancies. Universal Analytics tracked sessions based on the timeout session, which means a new session was triggered if an activity happened within the timeout session. GA4 evolved into a new concept called engaged sessions. Engaged sessions are based on user interactions or an event. In Universal Analytics, the user was tracked based on the unique identifier in their cookie, so if they went to your site on a different device they would be counted as a new user. Furthermore, GA4 also uses the unique identifier, but it can handle tracking cross-device and cross platform, allowing for a more accurate understanding of the user across multiple sessions and devices. In Universal Analytics it was simple, Google was tracking the individual user so they could see their average time on each page. In GA4 the only way to get average time on page is to divide total engaged time by engaged sessions. If a user exits your page before triggering an event, the time spent on the page may not be accurate. These are examples of how both platforms have average time on page, sessions, users, bounce rates, etc., but are being tracked differently.', metadata={'url': 'https://www.infinitive.com/what-companies-should-expect-with-google-analytics-4/', 'title': 'What Companies Should Expect with Google Analytics 4 (GA4)', 'author': \"['Evina Denenberg']\", 'keywords': \"['ga4', 'analytics', 'engaged', 'google', 'data', 'expect', 'companies', 'user', 'sessions', 'tracking', 'universal', 'customer', 'page']\", 'summary': 'Universal Analytics tracked sessions based on the timeout session, which means a new session was triggered if an activity happened within the timeout session.\\nIn Universal Analytics it was simple, Google was tracking the individual user so they could see their average time on each page.\\nIn GA4 the only way to get average time on page is to divide total engaged time by engaged sessions.\\nUniversal Analytics was very successful at giving an overall view of the user journey along with how customers arrived at your website.\\nWith Universal Analytics’ discontinuation right around the corner, companies will have to adapt to using Google Analytics 4’s capabilities.', 'metadata': \"defaultdict(<class 'dict'>, {'viewport': 'width=device-width, initial-scale=1', 'robots': 'index, follow, max-image-preview:large, max-snippet:-1, max-video-preview:-1', 'description': 'As the termination of Universal Analytics slowly creeps up on July 1st, many companies will be forced to migrate from Universal Analytics to Google As the termination of Universal Analytics in July slowly creeps up on us, many companies will be forced to migrate from Universal Analytics to Google analytics 4 (GA4). The primary distinction between Universal Analytics and GA4 lies in their focus. Universal Analytics focused on sessions and pageviews, whereas GA4 is based on events and parameters. In GA4, an event allows you to measure specific interactions or occurrences on your website or app.', 'og': {'locale': 'en_US', 'type': 'article', 'title': 'What Companies Should Expect with Google Analytics 4 (GA4)', 'description': 'As the termination of Universal Analytics slowly creeps up on July 1st, many companies will be forced to migrate from Universal Analytics to Google As the termination of Universal Analytics in July slowly creeps up on us, many companies will be forced to migrate from Universal Analytics to Google analytics 4 (GA4). The primary distinction between Universal Analytics and GA4 lies in their focus. Universal Analytics focused on sessions and pageviews, whereas GA4 is based on events and parameters. In GA4, an event allows you to measure specific interactions or occurrences on your website or app.', 'url': 'https://www.infinitive.com/what-companies-should-expect-with-google-analytics-4/', 'site_name': 'Infinitive', 'image': {'identifier': 'https://www.infinitive.com/wp-content/uploads/2023/06/google-analytics-scaled.webp', 'width': 2560, 'height': 1444, 'type': 'image/jpeg'}}, 'article': {'publisher': 'https://www.facebook.com/Infinitive/', 'published_time': '2023-06-30T00:56:28+00:00'}, 'author': 'Evina Denenberg', 'twitter': {'card': 'summary_large_image', 'creator': '@infinitiveinc', 'site': '@infinitiveinc', 'label1': 'Written by', 'data1': 'Evina Denenberg', 'label2': 'Est. reading time', 'data2': '3 minutes'}, 'generator': 'Elementor 3.15.2; features: e_dom_optimization, e_optimized_assets_loading, e_optimized_css_loading; settings: css_print_method-external, google_font-enabled, font_display-auto', 'msapplication-TileImage': 'https://www.infinitive.com/wp-content/uploads/2020/09/orange-bug.svg'})\", 'publishing_timestamp': '2023-06-30 00:56:28+00:00'}), Document(page_content='Data analytics helps companies increase efficiency and improve performance by letting them discover patterns in data. It answers both strategic and tactical business questions by collecting, transforming, and analyzing data generated by business systems applications. Understanding how data moves through various data sources is a prerequisite for building a data analytics pipeline and transforming collected data into meaningful insights for users.', metadata={'url': 'https://www.infinitive.com/serverless-data-analytics-101/', 'title': 'Serverless Data Analytics 101', 'author': \"['Tammy Lawson']\", 'keywords': \"['provides', 'analytics', '101', 'serverless', 'platform', 's3', 'aws', 'data', 'services', 'need', 'architecture']\", 'summary': 'Data analytics helps companies increase efficiency and improve performance by letting them discover patterns in data.\\nUnderstanding how data moves through various data sources is a prerequisite for building a data analytics pipeline and transforming collected data into meaningful insights for users.\\nServerless data analytics provides many benefits and the agility required of a modern data platform solution.\\nWhat is serverless data analytics?\\nData ingestionAWS Data Migration Services (AWS DMS) can connect to various data sources (both RDBMS and NoSQL) and ingest data into a central data lake.', 'metadata': \"defaultdict(<class 'dict'>, {'viewport': 'width=device-width, initial-scale=1', 'robots': 'index, follow, max-image-preview:large, max-snippet:-1, max-video-preview:-1', 'description': 'Serverless analytics platforms are scalable, cheaper, and allow great flexibility for ingesting new datasets.', 'og': {'locale': 'en_US', 'type': 'article', 'title': 'Serverless Data Analytics 101', 'description': 'Serverless analytics platforms are scalable, cheaper, and allow great flexibility for ingesting new datasets.', 'url': 'https://www.infinitive.com/serverless-data-analytics-101/', 'site_name': 'Infinitive', 'image': 'https://www.infinitive.com//wp-content/webpc-passthru.php?src=https://www.infinitive.com/wp-content/uploads/2021/05/Picture1.png&nocache=1'}, 'article': {'publisher': 'https://www.facebook.com/Infinitive/', 'published_time': '2021-05-28T12:27:28+00:00', 'modified_time': '2023-04-11T13:37:33+00:00'}, 'author': 'Tammy Lawson', 'twitter': {'card': 'summary_large_image', 'creator': '@infinitiveinc', 'site': '@infinitiveinc', 'label1': 'Written by', 'data1': 'Tammy Lawson', 'label2': 'Est. reading time', 'data2': '5 minutes'}, 'generator': 'Elementor 3.15.2; features: e_dom_optimization, e_optimized_assets_loading, e_optimized_css_loading; settings: css_print_method-external, google_font-enabled, font_display-auto', 'msapplication-TileImage': 'https://www.infinitive.com/wp-content/uploads/2020/09/orange-bug.svg'})\", 'publishing_timestamp': '2021-05-28 12:27:28+00:00'})]}\n"
     ]
    }
   ],
   "source": [
    "run_configured_llm(embedding_model_path='./sentence_embedding_model_512', chromadb_path='./search_chromadb_512', repo_id=\"bigscience/bloom-560m\", model_kwargs={\"temperature\":1e-10, \"max_length\":250}, chain_type='stuff', query='what is universal analytics good at?', template=template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a38873d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "run_configured_llm(embedding_model_path='./search_embedding_model', chromadb_path='./search_chromadb', repo_id=\"bigscience/bloom-560m\", model_kwargs={\"temperature\":1e-10, \"max_length\":250}, chain_type='stuff', query='what is universal analytics good at?', template=template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ffb26242",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'query': 'what is universal analytics good at?', 'result': ' - universal analytics is a good tool for analyzing the data of a website.\\n     - universal analytics is a good tool for analyzing the data of a website.\\n     - universal analytics is a good tool for analyzing the data of a website.\\n     - universal analytics is a good tool for analyzing the data of a website.\\n     - universal analytics is a good tool for analyzing the data of a website.\\n     - universal analytics is a good tool for analyzing the data of a website.\\n     - universal analytics is a good tool for analyzing the data of a website.\\n     - universal analytics is a good tool for analyzing the data of a website.\\n     - universal analytics is a good tool for analyzing the data of a website.\\n     - universal analytics is a good tool for analyzing the data of a website.\\n     - universal analytics is a good tool for analyzing the data of a website.\\n     - universal analytics is a good tool for analyzing the data of a website.\\n     - universal analytics is a good tool for analyzing the data of a website.\\n     - universal analytics is a good tool for analyzing the data of a website.\\n     - universal analytics is a good tool for analyzing the data of a website.\\n     - universal analytics is a good tool for analyzing the data of a website.\\n     - universal analytics is a good tool for analyzing the data of a website.\\n     - universal analytics is a good tool for analyzing the data of a website.\\n     - universal analytics is a good tool for analyzing the data of a website.\\n     - universal analytics is a good tool for analyzing the data of a website.\\n     - universal analytics is a good tool for analyzing the data of a website.\\n     - universal analytics is a good tool for analyzing the data of a website.\\n     - universal analytics is a good tool for analyzing the data of a website.\\n     - universal analytics is a good tool for analyzing the data of a website.\\n     - universal analytics is a good tool for analyzing the data of a website.\\n     - universal analytics is a good tool for analyzing the data of a website.\\n     - universal analytics is a good tool for analyzing the data', 'source_documents': []}\n"
     ]
    }
   ],
   "source": [
    "run_configured_llm(embedding_model_path='./search_embedding_model', chromadb_path='./recursive_search_chromadb', repo_id=\"bigscience/bloom-560m\", model_kwargs={\"temperature\":1e-10, \"max_length\":500}, chain_type='stuff', query='what is universal analytics good at?', template=template)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf0566a",
   "metadata": {},
   "source": [
    "# Falcon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7121892f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "run_configured_llm(embedding_model_path='./sentence_embedding_model_512', chromadb_path='./search_chromadb_512', repo_id=\"tiiuae/falcon-7b\", model_kwargs={\"temperature\":1e-10, \"max_length\":500}, chain_type='stuff', query='what is universal analytics good at?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "869acdc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_configured_llm(embedding_model_path='./search_embedding_model', chromadb_path='./search_chromadb', repo_id=\"tiiuae/falcon-7b\", model_kwargs={\"temperature\":1e-10, \"max_length\":250}, chain_type='stuff', query='what is universal analytics good at?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "21e63c0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'query': 'what is universal analytics good at?', 'result': '', 'source_documents': []}\n"
     ]
    }
   ],
   "source": [
    "run_configured_llm(embedding_model_path='./search_embedding_model', chromadb_path='./recursive_search_chromadb', repo_id=\"tiiuae/falcon-7b\", model_kwargs={\"temperature\":1e-10, \"max_length\":500}, chain_type='stuff', query='what is universal analytics good at?', template=template)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c2e899",
   "metadata": {},
   "source": [
    "# GPT2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3c642a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "run_configured_llm(embedding_model_path='./sentence_embedding_model_512', chromadb_path='./search_chromadb_512', repo_id=\"gpt2\", model_kwargs={\"temperature\":1e-10, \"max_length\":500}, chain_type='stuff', query='what is universal analytics good at?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55060b6a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "run_configured_llm(embedding_model_path='./search_embedding_model', chromadb_path='./search_chromadb', repo_id=\"gpt2\", model_kwargs={\"temperature\":1e-10, \"max_length\":250}, chain_type='stuff', query='what is universal analytics good at?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "88e9e5c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'query': 'what is data transformation?', 'result': '                                                                                                                                                                                                                                                                                                                                                                                                                                ', 'source_documents': []}\n"
     ]
    }
   ],
   "source": [
    "run_configured_llm(embedding_model_path='./search_embedding_model', chromadb_path='./recursive_search_chromadb', repo_id=\"gpt2\", model_kwargs={\"temperature\":1e-10, \"max_length\":500}, chain_type='stuff', query='what is data transformation?')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07443bf3",
   "metadata": {},
   "source": [
    "# Flan T5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "dedc1e9e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'query': 'what is universal analytics good at?', 'result': 'not enough information', 'source_documents': []}\n"
     ]
    }
   ],
   "source": [
    "run_configured_llm(embedding_model_path='./search_embedding_model', chromadb_path='./recursive_search_chromadb', repo_id='google/flan-t5-base', model_kwargs={\"temperature\":.5, \"max_length\":500}, chain_type='stuff', query='what is universal analytics good at?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "51588834",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_template = \"\"\"If context is given and is relevant to the question, answer the question using the context. Otherwise, if context is not given, just say \"I couldn't find a post that answers this question. Please try another question.\". Do not answer the question if you are unsure. \n",
    "\n",
    "    Question: {question}\n",
    "    Context: {context}\n",
    "    Answer:\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cab9d4ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'query': 'what is universal analytics good at?', 'result': \"I couldn't find a post that answers this question. Please try another question.\", 'source_documents': []}\n"
     ]
    }
   ],
   "source": [
    "run_configured_llm(embedding_model_path='./search_embedding_model', chromadb_path='./recursive_search_chromadb', repo_id='google/flan-t5-base', model_kwargs={\"temperature\":.5, \"max_length\":500}, chain_type='stuff', query='what is universal analytics good at?', template=test_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cef37e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
